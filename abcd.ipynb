{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "# ADNI Dataset Model Cross-Validation Pipeline\n",
    "## Features: GPU acceleration, timeout support, comprehensive error handling, and automatic result archiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_configs",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_models = [\n",
    "    'vit_base_patch16_224.augreg2_in21k_ft_in1k',\n",
    "    'vit_base_patch16_224',\n",
    "    \"vit_tiny_patch16_224.augreg_in21k_ft_in1k\",\n",
    "    \"vit_tiny_patch16_224\",\n",
    "    'swin_base_patch4_window7_224.ms_in22k_ft_in1k',\n",
    "    'swin_base_patch4_window7_224',\n",
    "    'maxvit_tiny_224',\n",
    "    'tf_efficientnet_b4.ns_jft_in1k',\n",
    "    'convnext_small.fb_in22k_ft_in1k'\n",
    "]\n",
    "\n",
    "medium_models = [\n",
    "    'tf_efficientnetv2_s.in21k_ft_in1k',\n",
    "    'convnext_tiny.fb_in22k_ft_in1k',\n",
    "    'coatnet_0_rw_224.sw_in1k',\n",
    "    'resnet50.a1_in1k',\n",
    "    'resnext50_32x4d.a1h_in1k',\n",
    "    'densenet121.ra_in1k',\n",
    "    'inception_v3',\n",
    "    'xception',\n",
    "    'vgg16_bn'\n",
    "]\n",
    "\n",
    "light_models = [\n",
    "    'mobilevit_s.cvnets_in1k',\n",
    "    'efficientformer_l1.snap_dist_in1k',\n",
    "    'poolformer_s12.sail_in1k',\n",
    "    'resnet18',\n",
    "    'efficientnet_b0',\n",
    "    'mobilenetv3_large_100.ra_in1k',\n",
    "    'ghostnet_100.in1k'\n",
    "]\n",
    "\n",
    "def get_model_batches():\n",
    "    batches = []\n",
    "    \n",
    "    def chunk_list(lst, n):\n",
    "        for i in range(0, len(lst), n):\n",
    "            yield lst[i:i + n]\n",
    "\n",
    "    for chunk in chunk_list(heavy_models, 3):\n",
    "        batches.append(chunk)\n",
    "    for chunk in chunk_list(medium_models, 5):\n",
    "        batches.append(chunk)\n",
    "    for chunk in chunk_list(light_models, 8):\n",
    "        batches.append(chunk)\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('.')))\n",
    "try:\n",
    "    from module.config import SUBPROCESS_TIMEOUT\n",
    "    print(f\"Loaded timeout: {SUBPROCESS_TIMEOUT}s ({SUBPROCESS_TIMEOUT/3600:.1f}h)\")\n",
    "except ImportError:\n",
    "    SUBPROCESS_TIMEOUT = 14400\n",
    "    print(f\"Default timeout: {SUBPROCESS_TIMEOUT}s ({SUBPROCESS_TIMEOUT/3600:.1f}h)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subprocess_template",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBPROCESS_TEMPLATE = r\"\"\"\n",
    "import sys\n",
    "from module.cross_validation import Cross_Validator\n",
    "from module.utils import Logger\n",
    "\n",
    "def run_batch():\n",
    "    models = __models_list__\n",
    "    use_aug = __augmentation__\n",
    "\n",
    "    logger = Logger(\"batch_\" + str(hash(str(models)))[:8])\n",
    "    logger.info(f\"Starting validation for {models}\")\n",
    "    \n",
    "    try:\n",
    "        validator = Cross_Validator(models, logger, use_aug=use_aug)\n",
    "        validator.run()\n",
    "        logger.info(\"Validation complete\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Batch failed: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_batch()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subprocess_runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subprocess(models_list, use_aug):\n",
    "    script_filename = \"temp_runner.py\"\n",
    "    script_path = os.path.join(\"module\", script_filename)\n",
    "    \n",
    "    script_content = SUBPROCESS_TEMPLATE.replace(\"__models_list__\", str(models_list)) \\\n",
    "                                        .replace(\"__augmentation__\", str(use_aug))\n",
    "    \n",
    "    with open(script_path, \"w\") as f:\n",
    "        f.write(script_content)\n",
    "    \n",
    "    print(f\"üöÄ Launching: {models_list}\")\n",
    "    print(f\"   Timeout: {SUBPROCESS_TIMEOUT/3600:.1f}h\")\n",
    "\n",
    "    try:\n",
    "        module_path = f\"module.{script_filename[:-3]}\"\n",
    "        subprocess.run(\n",
    "            [sys.executable, \"-m\", module_path], \n",
    "            check=True,\n",
    "            timeout=SUBPROCESS_TIMEOUT\n",
    "        )\n",
    "    finally:\n",
    "        if os.path.exists(script_path):\n",
    "            os.remove(script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "queue_runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_queue(use_aug):\n",
    "    run_id = f\"AUG_{use_aug}_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "    total_batches = completed = timeout = failed = 0\n",
    "    errors = []\n",
    "    \n",
    "    print(f\"--- Queue {run_id} ---\")\n",
    "\n",
    "    try:\n",
    "        batches = get_model_batches()\n",
    "        total_batches = len(batches)\n",
    "\n",
    "        for i, batch in enumerate(batches):\n",
    "            print(f\"\\n>>> Batch {i+1}/{total_batches}: {batch}\")\n",
    "            try:\n",
    "                run_subprocess(batch, use_aug)\n",
    "                completed += 1\n",
    "                print(f\"‚úÖ Batch {i+1} done\")\n",
    "            except subprocess.TimeoutExpired:\n",
    "                timeout += 1\n",
    "                errors.append(f\"Batch {i+1} TIMEOUT\")\n",
    "                print(f\"‚è∞ Timeout\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                failed += 1\n",
    "                errors.append(f\"Batch {i+1} ERROR: {e}\")\n",
    "                print(f\"‚ùå Failed\")\n",
    "            except Exception as e:\n",
    "                failed += 1\n",
    "                errors.append(f\"Batch {i+1}: {traceback.format_exc()}\")\n",
    "                print(f\"‚ùå Error\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"‚ö†Ô∏è User interrupt\")\n",
    "    \n",
    "    summary = f\"\"\"\n",
    "=== RUN SUMMARY ===\n",
    "ID: {run_id}\n",
    "Completed: {completed}/{total_batches}\n",
    "Timeout: {timeout}\n",
    "Failed: {failed}\n",
    "Errors: {len(errors)}\n",
    "\"\"\"\n",
    "    print(summary)\n",
    "    \n",
    "    with open(f\"REPORT_{run_id}.txt\", \"w\") as f:\n",
    "        f.write(summary + \"\\n\\n\" + \"\\n\".join(errors))\n",
    "    \n",
    "    return {'run_id': run_id, 'completed': completed, 'timeout': timeout, 'failed': failed, 'total': total_batches}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zip_helper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_output_directory(summaries):\n",
    "    import zipfile\n",
    "    \n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        return\n",
    "    \n",
    "    zip_name = f\"Results_{datetime.now().strftime('%Y%m%d_%H%M')}.zip\"\n",
    "    \n",
    "    print(\"\\nüì¶ ZIPPING OUTPUT\")\n",
    "    \n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            files = 0\n",
    "            for root, dirs, filelist in os.walk(OUTPUT_DIR):\n",
    "                for file in filelist:\n",
    "                    filepath = os.path.join(root, file)\n",
    "                    zipf.write(filepath, os.path.relpath(filepath, '.'))\n",
    "                    files += 1\n",
    "        \n",
    "        size_mb = os.path.getsize(zip_name) / (1024*1024)\n",
    "        print(f\"‚úÖ {zip_name} ({size_mb:.1f}MB, {files} files)\")\n",
    "\n",
    "        print(\"\\nüìä SUMMARY:\")\n",
    "        \n",
    "        for s in summaries:\n",
    "            status = \"‚úì\" if s['completed'] == s['total'] else \"‚ö†\"\n",
    "            print(f\"\\n{status} {s['run_id']}: {s['completed']}/{s['total']}\")\n",
    "        \n",
    "        print(\"\\nüéâ COMPLETE!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Zip failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = []\n",
    "\n",
    "print(\"üöÄ NON-AUGMENTED RUN\")\n",
    "summaries.append(run_queue(False))\n",
    "\n",
    "print(\"\\nüöÄ AUGMENTED RUN\")\n",
    "summaries.append(run_queue(True))\n",
    "\n",
    "zip_output_directory(summaries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
