{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "# ADNI Dataset Model Cross-Validation Pipeline\n",
    "## Features: GPU acceleration, timeout support, comprehensive error handling, automatic result archiving, and advanced classifier support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_configs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model batches organized by computational requirements\n",
    "heavy_models = [\n",
    "    'vit_base_patch16_224.augreg2_in21k_ft_in1k',\n",
    "    'vit_base_patch16_224',\n",
    "    \"vit_tiny_patch16_224.augreg_in21k_ft_in1k\",\n",
    "    \"vit_tiny_patch16_224\",\n",
    "    'swin_base_patch4_window7_224.ms_in22k_ft_in1k',\n",
    "    'swin_base_patch4_window7_224',\n",
    "    'maxvit_tiny_224',\n",
    "    'tf_efficientnet_b4.ns_jft_in1k',\n",
    "    'convnext_small.fb_in22k_ft_in1k'\n",
    "]\n",
    "\n",
    "medium_models = [\n",
    "    'tf_efficientnetv2_s.in21k_ft_in1k',\n",
    "    'convnext_tiny.fb_in22k_ft_in1k',\n",
    "    'coatnet_0_rw_224.sw_in1k',\n",
    "    'resnet50.a1_in1k',\n",
    "    'resnext50_32x4d.a1h_in1k',\n",
    "    'densenet121.ra_in1k',\n",
    "    'inception_v3',\n",
    "    'xception',\n",
    "    'vgg16_bn'\n",
    "]\n",
    "\n",
    "light_models = [\n",
    "    'mobilevit_s.cvnets_in1k',\n",
    "    'efficientformer_l1.snap_dist_in1k',\n",
    "    'poolformer_s12.sail_in1k',\n",
    "    'resnet18',\n",
    "    'efficientnet_b0',\n",
    "    'mobilenetv3_large_100.ra_in1k',\n",
    "    'ghostnet_100.in1k'\n",
    "]\n",
    "\n",
    "def get_model_batches():\n",
    "    \"\"\"Organize models into processing batches based on computational requirements.\"\"\"\n",
    "    batches = []\n",
    "    \n",
    "    def chunk_list(lst, n):\n",
    "        for i in range(0, len(lst), n):\n",
    "            yield lst[i:i + n]\n",
    "\n",
    "    # Heavy models: 3 per batch\n",
    "    for chunk in chunk_list(heavy_models, 3):\n",
    "        batches.append(chunk)\n",
    "    \n",
    "    # Medium models: 5 per batch\n",
    "    for chunk in chunk_list(medium_models, 5):\n",
    "        batches.append(chunk)\n",
    "    \n",
    "    # Light models: 8 per batch\n",
    "    for chunk in chunk_list(light_models, 8):\n",
    "        batches.append(chunk)\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classifier_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: Classifier Configuration\n",
    "# Map specific models to specific classifiers\n",
    "# If a model is not in this map, it will use 'baseline' by default\n",
    "\n",
    "# Available classifiers:\n",
    "# - 'baseline': Standard CrossEntropy\n",
    "# - 'progressive': 3-phase discriminative fine-tuning (RECOMMENDED)\n",
    "# - 'evidential': Uncertainty quantification\n",
    "# - 'metric_learning': Prototypes + Triplet + Center Loss\n",
    "# - 'regularized': Manifold Mixup + Label Smoothing\n",
    "# - 'attention_enhanced': SE Blocks + Cosine Classifier\n",
    "# - 'progressive_evidential': Progressive + Evidential\n",
    "# - 'clinical_grade': Clinical deployment (5 techniques + SAM)\n",
    "# - 'hybrid_transformer': CNN + Transformer hybrid\n",
    "# - 'ultimate': All 10 techniques (maximum recall)\n",
    "# - 'all': Test all classifiers on this model\n",
    "\n",
    "MODEL_CLASSIFIER_MAP = {\n",
    "    # Example: Use progressive fine-tuning for ResNet models\n",
    "    'resnet18': 'progressive',\n",
    "    'resnet50.a1_in1k': 'progressive',\n",
    "    \n",
    "    # Example: Use clinical-grade for EfficientNet (high accuracy needed)\n",
    "    'tf_efficientnet_b4.ns_jft_in1k': 'clinical_grade',\n",
    "    \n",
    "    # Example: Use ultimate for your best model\n",
    "    # 'efficientnet_b0': 'ultimate',\n",
    "    \n",
    "    # Example: Test ALL classifiers on a specific model\n",
    "    # 'vit_tiny_patch16_224': 'all',\n",
    "}\n",
    "\n",
    "# Default classifier for models not in the map\n",
    "DEFAULT_CLASSIFIER = 'baseline'\n",
    "\n",
    "print(\"Classifier Configuration:\")\n",
    "print(f\"  Default: {DEFAULT_CLASSIFIER}\")\n",
    "print(f\"  Custom mappings: {len(MODEL_CLASSIFIER_MAP)}\")\n",
    "for model, clf in MODEL_CLASSIFIER_MAP.items():\n",
    "    print(f\"    {model}: {clf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('.')))\n",
    "try:\n",
    "    from module.config import SUBPROCESS_TIMEOUT\n",
    "    print(f\"Loaded timeout: {SUBPROCESS_TIMEOUT}s ({SUBPROCESS_TIMEOUT/3600:.1f}h)\")\n",
    "except ImportError:\n",
    "    SUBPROCESS_TIMEOUT = 12 * 3600\n",
    "    print(f\"Default timeout: {SUBPROCESS_TIMEOUT}s ({SUBPROCESS_TIMEOUT/3600:.1f}h)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subprocess_template",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED: Template now includes classifier mapping\n",
    "SUBPROCESS_TEMPLATE = r\"\"\"\n",
    "import sys\n",
    "from module.cross_validation import Cross_Validator\n",
    "from module.utils import Logger\n",
    "\n",
    "def run_batch():\n",
    "    models = __models_list__\n",
    "    classifier_map = __classifier_map__\n",
    "\n",
    "    logger = Logger(\"batch_\" + str(hash(str(models)))[:8])\n",
    "    logger.info(f\"Starting validation for {models}\")\n",
    "    logger.info(f\"Classifier mapping: {classifier_map}\")\n",
    "    \n",
    "    try:\n",
    "        validator = Cross_Validator(\n",
    "            models,\n",
    "            logger,\n",
    "            model_classifier_map=classifier_map\n",
    "        )\n",
    "        validator.run()\n",
    "        logger.info(\"Validation complete\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Batch failed: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_batch()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subprocess_runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subprocess(models_list, classifier_map=None):\n",
    "    \"\"\"Run a batch of models in a subprocess with classifier mapping.\n",
    "    \n",
    "    Args:\n",
    "        models_list: List of model names to train\n",
    "        classifier_map: Dict mapping model_name -> classifier_type\n",
    "                       If None, uses DEFAULT_CLASSIFIER for all models\n",
    "    \"\"\"\n",
    "    script_filename = \"temp_runner.py\"\n",
    "    script_path = os.path.join(\"module\", script_filename)\n",
    "    \n",
    "    # Create classifier map for this batch\n",
    "    if classifier_map is None:\n",
    "        batch_classifier_map = {\n",
    "            model: DEFAULT_CLASSIFIER for model in models_list\n",
    "        }\n",
    "    else :\n",
    "        # Filter to only include models in this batch\n",
    "        batch_classifier_map = {\n",
    "            model: classifier_map.get(model, DEFAULT_CLASSIFIER)\n",
    "            for model in models_list\n",
    "        }\n",
    "    \n",
    "    script_content = SUBPROCESS_TEMPLATE.replace(\"__models_list__\", str(models_list)) \\\n",
    "                                        .replace(\"__classifier_map__\", str(batch_classifier_map))\n",
    "    \n",
    "    with open(script_path, \"w\") as f:\n",
    "        f.write(script_content)\n",
    "    \n",
    "    print(f\"üöÄ Launching: {models_list}\")\n",
    "    print(f\"   Classifiers: {batch_classifier_map}\")\n",
    "    print(f\"   Timeout: {SUBPROCESS_TIMEOUT/3600:.1f}h\")\n",
    "\n",
    "    try:\n",
    "        module_path = f\"module.{script_filename[:-3]}\"\n",
    "        subprocess.run(\n",
    "            [sys.executable, \"-m\", module_path], \n",
    "            check=True,\n",
    "            timeout=SUBPROCESS_TIMEOUT\n",
    "        )\n",
    "    finally:\n",
    "        if os.path.exists(script_path):\n",
    "            os.remove(script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "queue_runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_queue(classifier_map=None):\n",
    "    \"\"\"Run all model batches with classifier mapping.\n",
    "    \n",
    "    Args:\n",
    "        classifier_map: Dict mapping model_name -> classifier_type\n",
    "                       If None, uses DEFAULT_CLASSIFIER for all models\n",
    "    \"\"\"\n",
    "    run_id = f\"RUN_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "    total_batches = completed = timeout = failed = 0\n",
    "    errors = []\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING BATCH PROCESSING: {run_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if classifier_map:\n",
    "        print(f\"\\nClassifier Mapping ({len(classifier_map)} custom):\")\n",
    "        for model, clf in classifier_map.items():\n",
    "            print(f\"  {model}: {clf}\")\n",
    "    print(f\"Default Classifier: {DEFAULT_CLASSIFIER}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    try:\n",
    "        batches = get_model_batches()\n",
    "        total_batches = len(batches)\n",
    "\n",
    "        for i, batch in enumerate(batches):\n",
    "            print(f\"\\n{'>'*80}\")\n",
    "            print(f\">>> Batch {i+1}/{total_batches}\")\n",
    "            print(f\">>> Models: {batch}\")\n",
    "            print(f\"{'>'*80}\")\n",
    "            \n",
    "            try:\n",
    "                run_subprocess(batch, classifier_map)\n",
    "                completed += 1\n",
    "                print(f\"\\n‚úÖ Batch {i+1}/{total_batches} completed successfully\\n\")\n",
    "            except subprocess.TimeoutExpired:\n",
    "                timeout += 1\n",
    "                errors.append(f\"Batch {i+1} TIMEOUT after {SUBPROCESS_TIMEOUT/3600:.1f}h\")\n",
    "                print(f\"\\n‚è∞ Batch {i+1} TIMEOUT\\n\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                failed += 1\n",
    "                errors.append(f\"Batch {i+1} ERROR: {e}\")\n",
    "                print(f\"\\n‚ùå Batch {i+1} failed with error\\n\")\n",
    "            except Exception as e:\n",
    "                failed += 1\n",
    "                errors.append(f\"Batch {i+1}: {traceback.format_exc()}\")\n",
    "                print(f\"\\n‚ùå Batch {i+1} failed with exception\\n\")\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è User interrupt detected\\n\")\n",
    "    \n",
    "    # Summary Report\n",
    "    summary = f\"\"\"\n",
    "{'='*80}\n",
    "EXECUTION SUMMARY\n",
    "{'='*80}\n",
    "Run ID: {run_id}\n",
    "Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Results:\n",
    "  ‚úì Completed: {completed}/{total_batches}\n",
    "  ‚è∞ Timeout:   {timeout}\n",
    "  ‚ùå Failed:    {failed}\n",
    "  \n",
    "Success Rate: {100*completed/total_batches if total_batches > 0 else 0:.1f}%\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "    print(summary)\n",
    "    \n",
    "    # Save detailed report\n",
    "    report_file = f\"REPORT_{run_id}.txt\"\n",
    "    with open(report_file, \"w\") as f:\n",
    "        f.write(summary)\n",
    "        f.write(\"\\n\\nDETAILED ERRORS:\\n\")\n",
    "        f.write(\"\\n\".join(errors) if errors else \"No errors\")\n",
    "    \n",
    "    print(f\"üìÑ Detailed report saved to: {report_file}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'run_id': run_id,\n",
    "        'completed': completed,\n",
    "        'timeout': timeout,\n",
    "        'failed': failed,\n",
    "        'total': total_batches\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zip_helper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_output_directory(summary):\n",
    "    \"\"\"Archive output directory after successful completion.\"\"\"\n",
    "    import zipfile\n",
    "    \n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        print(f\"‚ö†Ô∏è Output directory '{OUTPUT_DIR}' not found. Nothing to zip.\")\n",
    "        return\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "    zip_name = f\"Results_{timestamp}.zip\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ARCHIVING RESULTS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            files = 0\n",
    "            for root, dirs, filelist in os.walk(OUTPUT_DIR):\n",
    "                for file in filelist:\n",
    "                    filepath = os.path.join(root, file)\n",
    "                    zipf.write(filepath, os.path.relpath(filepath, '.'))\n",
    "                    files += 1\n",
    "        \n",
    "        size_mb = os.path.getsize(zip_name) / (1024*1024)\n",
    "        print(f\"‚úÖ Archive created: {zip_name}\")\n",
    "        print(f\"   Size: {size_mb:.1f} MB\")\n",
    "        print(f\"   Files: {files}\")\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"EXECUTION SUMMARY\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        status = \"‚úÖ SUCCESS\" if summary['completed'] == summary['total'] else \"‚ö†Ô∏è PARTIAL\"\n",
    "        print(f\"\\nStatus: {status}\")\n",
    "        print(f\"Run ID: {summary['run_id']}\")\n",
    "        print(f\"Completed: {summary['completed']}/{summary['total']} batches\")\n",
    "        print(f\"Timeout: {summary['timeout']}\")\n",
    "        print(f\"Failed: {summary['failed']}\")\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"üéâ ALL PROCESSING COMPLETE!\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Archive creation failed: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN EXECUTION\n",
    "# Run all model batches with classifier configuration\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADNI CROSS-VALIDATION PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total Models: {len(heavy_models + medium_models + light_models)}\")\n",
    "print(f\"Total Batches: {len(get_model_batches())}\")\n",
    "print(f\"Timeout per Batch: {SUBPROCESS_TIMEOUT/3600:.1f}h\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Run with classifier mapping\n",
    "summary = run_queue(classifier_map=MODEL_CLASSIFIER_MAP)\n",
    "\n",
    "# Archive results\n",
    "zip_output_directory(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional_single_batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Test single batch (for debugging)\n",
    "# Uncomment to run a single batch instead of all batches\n",
    "\n",
    "# test_batch = ['resnet18']\n",
    "# test_classifier_map = {\n",
    "#     'resnet18': 'progressive'  # or 'all' to test all classifiers\n",
    "# }\n",
    "\n",
    "# print(\"\\nüß™ TESTING SINGLE BATCH\\n\")\n",
    "# run_subprocess(test_batch, test_classifier_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional_quick_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Quick test with all classifiers on one model\n",
    "# Uncomment to compare all classifiers on a single model\n",
    "\n",
    "# quick_test_batch = ['resnet18']\n",
    "# quick_test_map = {'resnet18': 'all'}  # Test ALL classifiers\n",
    "\n",
    "# print(\"\\nüî¨ QUICK TEST: All Classifiers on ResNet18\\n\")\n",
    "# run_subprocess(quick_test_batch, quick_test_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
