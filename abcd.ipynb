{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f63b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"uraninjo/augmented-alzheimer-mri-dataset\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34940e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "816b150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_models = [\n",
    "    'vit_base_patch16_224.augreg2_in21k_ft_in1k',\n",
    "    'vit_base_patch16_224',\n",
    "    \"vit_tiny_patch16_224.augreg_in21k_ft_in1k\",\n",
    "    \"vit_tiny_patch16_224\",\n",
    "    'swin_base_patch4_window7_224.ms_in22k_ft_in1k',\n",
    "    'swin_base_patch4_window7_224',\n",
    "    'maxvit_tiny_224',\n",
    "    \n",
    "    'tf_efficientnet_b4.ns_jft_in1k',  # 380x380 resolution\n",
    "    'convnext_small.fb_in22k_ft_in1k'  # Deep modern CNN\n",
    "]\n",
    "\n",
    "medium_models = [\n",
    "    'tf_efficientnetv2_s.in21k_ft_in1k', # 300x300 resolution\n",
    "    'convnext_tiny.fb_in22k_ft_in1k',\n",
    "    'coatnet_0_rw_224.sw_in1k',\n",
    "    \n",
    "    'resnet50.a1_in1k',\n",
    "    'resnext50_32x4d.a1h_in1k',\n",
    "    'densenet121.ra_in1k',\n",
    "    'inception_v3',\n",
    "    'xception',\n",
    "    'vgg16_bn'\n",
    "]\n",
    "\n",
    "light_models = [\n",
    "    'mobilevit_s.cvnets_in1k',\n",
    "    'efficientformer_l1.snap_dist_in1k',\n",
    "    'poolformer_s12.sail_in1k',\n",
    "\n",
    "    'resnet18',\n",
    "    'efficientnet_b0',\n",
    "    'mobilenetv3_large_100.ra_in1k',\n",
    "    'ghostnet_100.in1k'\n",
    "]\n",
    "\n",
    "def get_model_batches():\n",
    "    \"\"\"\n",
    "    Returns a list of dictionaries. Each dictionary contains:\n",
    "    - 'models': List of model names\n",
    "    - 'config': Dictionary of training configurations (batch_size, epochs, img_size)\n",
    "    \"\"\"\n",
    "    \n",
    "    batches = []\n",
    "    \n",
    "    # Helper to chunk lists if they are too long for one subprocess\n",
    "    def chunk_list(lst, n):\n",
    "        for i in range(0, len(lst), n):\n",
    "            yield lst[i:i + n]\n",
    "\n",
    "    # Create Batches\n",
    "    for chunk in chunk_list(heavy_models, 3): # Run 3 heavy models per subprocess\n",
    "        batches.append(chunk)\n",
    "    \n",
    "    for chunk in chunk_list(medium_models, 5): # Run 5 medium models per subprocess\n",
    "        batches.append(chunk)\n",
    "    \n",
    "    for chunk in chunk_list(light_models, 8): # Run 5 medium models per subprocess\n",
    "        batches.append(chunk)\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646c6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from hf_manager import HFBackupManager\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RESULTS_DIR = \"output\" # The folder your subprocess writes to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abad2ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBPROCESS_TEMPLATE = r\"\"\"\n",
    "import sys\n",
    "from .cross_validation import Cross_Validator\n",
    "from .utils import Logger\n",
    "\n",
    "def run_batch():\n",
    "    print(\"--- Subprocess Started ---\")\n",
    "    \n",
    "    # Placeholders replaced by the main script\n",
    "    models = __models_list__\n",
    "    use_aug = __augmentation__\n",
    "\n",
    "    # logic\n",
    "    logger = Logger(\"05_12_2025\")\n",
    "    logger.info(f\"Starting Validation for {models}\")\n",
    "    \n",
    "    validator = Cross_Validator(models, logger, use_aug = use_aug)\n",
    "    validator.run()\n",
    "    \n",
    "    logger.info(\"Validation Complete\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_batch()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subprocess(models_list, use_aug):\n",
    "    # Name of the temporary file inside the package\n",
    "    # It must be inside 'module' folder to work with -m module.name\n",
    "    script_filename = \"temp_runner.py\"\n",
    "    script_path = os.path.join(\"module\", script_filename)\n",
    "    \n",
    "    # 2. FILL TEMPLATE & WRITE TO DISK\n",
    "    script_content = SUBPROCESS_TEMPLATE.replace(\"__models_list__\", str(models_list)) \\\n",
    "                                        .replace(\"__augmentation__\", str(use_aug))\n",
    "    \n",
    "    with open(script_path, \"w\") as f:\n",
    "        f.write(script_content)\n",
    "    \n",
    "    print(f\"ðŸš€ Launching subprocess for: {models_list}\")\n",
    "\n",
    "    try:\n",
    "        # 3. RUN AS MODULE\n",
    "        # Syntax: python -m package_name.script_name_without_extension\n",
    "        # We run this from the root directory (parent of 'module')\n",
    "        module_path = f\"module.{script_filename[:-3]}\" # removes .py\n",
    "        \n",
    "        subprocess.run(\n",
    "            [sys.executable, \"-m\", module_path], \n",
    "            check=True\n",
    "        )\n",
    "    finally:\n",
    "        # 4. CLEANUP\n",
    "        if os.path.exists(script_path):\n",
    "            os.remove(script_path)\n",
    "            print(\"ðŸ§¹ Cleanup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0368df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_queue(use_aug):\n",
    "    # 1. GENERATE RUN ID\n",
    "    run_id = f\"AUG_{use_aug}_RUN_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "    \n",
    "    # 2. STATE TRACKING\n",
    "    total_batches = 0\n",
    "    completed_batches = 0\n",
    "    run_status = \"Success\"\n",
    "    errors = []\n",
    "    \n",
    "    print(f\"--- Starting Queue {run_id} ---\")\n",
    "\n",
    "    try:\n",
    "        batches = get_model_batches()\n",
    "        total_batches = len(batches)\n",
    "\n",
    "        for i, batch in enumerate(batches):\n",
    "            batch_id = i + 1\n",
    "            print(f\"\\n>>> [Master] Launching Batch {batch_id} / {total_batches}\")\n",
    "            print(f\"Models: {batch}\")\n",
    "\n",
    "            # --- A. RUN SUBPROCESS ---\n",
    "            try:\n",
    "                run_subprocess(batch, use_aug)\n",
    "                \n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"âŒ Batch {batch_id} crashed: {e}\")\n",
    "                errors.append(f\"Batch {batch_id} Process Error: {str(e)}\")\n",
    "                continue \n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nâš ï¸ Interrupted by User!\")\n",
    "        run_status = \"Stopped by User\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nâŒ Critical Master Script Error: {e}\")\n",
    "        run_status = \"Crashed\"\n",
    "        errors.append(traceback.format_exc())\n",
    "\n",
    "    finally:\n",
    "        # --- UPLOAD STATUS TO HUGGING FACE ---\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ðŸ›‘ EXECUTION ENDED - UPLOADING LOG\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        if not errors :\n",
    "            error_text = \"None\"\n",
    "        else :\n",
    "            error_text = \"\\n\".join(f\"\\n--- Error {i}\\n{e}\" for i, e in enumerate(errors, start = 1))\n",
    "        \n",
    "        remaining = total_batches - completed_batches\n",
    "        summary_text = f\"\"\"\n",
    "=== TRAINING RUN SUMMARY ===\n",
    "Run ID: {run_id}\n",
    "Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Final Status: {run_status}\n",
    "\n",
    "Batches Uploaded: {completed_batches}\n",
    "Batches Failed/Skipped: {remaining}\n",
    "Total Scheduled: {total_batches}\n",
    "\n",
    "------ Error Logs ------\n",
    "{error_text}\n",
    "        \"\"\"\n",
    "        \n",
    "        filename = f\"REPORT_{run_id}.txt\"\n",
    "        \n",
    "        with open(filename, \"w\", encoding = \"utf-8\") as f:\n",
    "            f.write(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2d3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Queue AUG_False_RUN_20251205_1819 ---\n",
      "\n",
      ">>> [Master] Launching Batch 1 / 6\n",
      "Models: ['vit_base_patch16_224.augreg2_in21k_ft_in1k', 'vit_base_patch16_224', 'vit_tiny_patch16_224.augreg_in21k_ft_in1k']\n",
      "ðŸš€ Launching subprocess for: ['vit_base_patch16_224.augreg2_in21k_ft_in1k', 'vit_base_patch16_224', 'vit_tiny_patch16_224.augreg_in21k_ft_in1k']\n"
     ]
    }
   ],
   "source": [
    "run_queue(False)\n",
    "run_queue(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
