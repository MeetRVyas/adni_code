{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "# ADNI Dataset Model Cross-Validation Pipeline\n",
    "## Features: GPU acceleration, timeout support, comprehensive error handling, automatic result archiving, and advanced classifier support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_configs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model batches organized by computational requirements\n",
    "heavy_models = [\n",
    "    'vit_base_patch16_224.augreg2_in21k_ft_in1k',\n",
    "    'vit_base_patch16_224',\n",
    "    \"vit_tiny_patch16_224.augreg_in21k_ft_in1k\",\n",
    "    \"vit_tiny_patch16_224\",\n",
    "    'swin_base_patch4_window7_224.ms_in22k_ft_in1k',\n",
    "    'swin_base_patch4_window7_224',\n",
    "    'maxvit_tiny_224',\n",
    "    'tf_efficientnet_b4.ns_jft_in1k',\n",
    "    'convnext_small.fb_in22k_ft_in1k'\n",
    "]\n",
    "\n",
    "medium_models = [\n",
    "    'tf_efficientnetv2_s.in21k_ft_in1k',\n",
    "    'convnext_tiny.fb_in22k_ft_in1k',\n",
    "    'coatnet_0_rw_224.sw_in1k',\n",
    "    'resnet50.a1_in1k',\n",
    "    'resnext50_32x4d.a1h_in1k',\n",
    "    'densenet121.ra_in1k',\n",
    "    'inception_v3',\n",
    "    'xception',\n",
    "    'vgg16_bn'\n",
    "]\n",
    "\n",
    "light_models = [\n",
    "    'mobilevit_s.cvnets_in1k',\n",
    "    'efficientformer_l1.snap_dist_in1k',\n",
    "    'poolformer_s12.sail_in1k',\n",
    "    'resnet18',\n",
    "    'efficientnet_b0',\n",
    "    'mobilenetv3_large_100.ra_in1k',\n",
    "    'ghostnet_100.in1k'\n",
    "]\n",
    "\n",
    "def get_model_batches():\n",
    "    \"\"\"Organize models into processing batches based on computational requirements.\"\"\"\n",
    "    batches = []\n",
    "    \n",
    "    def chunk_list(lst, n):\n",
    "        for i in range(0, len(lst), n):\n",
    "            yield lst[i:i + n]\n",
    "\n",
    "    # Heavy models: 3 per batch\n",
    "    for chunk in chunk_list(heavy_models, 3):\n",
    "        batches.append(chunk)\n",
    "    \n",
    "    # Medium models: 5 per batch\n",
    "    for chunk in chunk_list(medium_models, 5):\n",
    "        batches.append(chunk)\n",
    "    \n",
    "    # Light models: 8 per batch\n",
    "    for chunk in chunk_list(light_models, 8):\n",
    "        batches.append(chunk)\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classifier_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map specific models to specific classifiers\n",
    "# If a model is not in this map, it will use 'baseline' by default\n",
    "\n",
    "# Available classifiers:\n",
    "# - 'baseline': Standard CrossEntropy\n",
    "# - 'progressive': 3-phase discriminative fine-tuning (RECOMMENDED)\n",
    "# - 'evidential': Uncertainty quantification\n",
    "# - 'metric_learning': Prototypes + Triplet + Center Loss\n",
    "# - 'regularized': Manifold Mixup + Label Smoothing\n",
    "# - 'attention_enhanced': SE Blocks + Cosine Classifier\n",
    "# - 'progressive_evidential': Progressive + Evidential\n",
    "# - 'clinical_grade': Clinical deployment (5 techniques + SAM)\n",
    "# - 'hybrid_transformer': CNN + Transformer hybrid\n",
    "# - 'ultimate': All 10 techniques (maximum recall)\n",
    "# - 'all': Test all classifiers on this model\n",
    "\n",
    "# Meet\n",
    "# MODEL_CLASSIFIER_MAP = {\n",
    "#     'resnet18': 'all'\n",
    "# }\n",
    "# MODEL_CLASSIFIER_MAP = {\n",
    "#     'resnet18': 'ultimate'\n",
    "# }\n",
    "# MODEL_CLASSIFIER_MAP = {\n",
    "#     'resnet50.a1_in1k': ['evidental', \"progressive_evidental\"],\n",
    "#     \"resnext50_32x4d.a1h_in1k\" : [\"clinical_grade\", \"metric_learning\"]\n",
    "# }\n",
    "\n",
    "# Prince\n",
    "# MODEL_CLASSIFIER_MAP = {\n",
    "#     \"swin_base_patch4_window7_224.ms_in22k_ft_in1k\" : [\"evidental\", \"progressive\", \"attention_enhanced\"]\n",
    "# }\n",
    "# MODEL_CLASSIFIER_MAP = {\n",
    "#     \"tf_efficientnet_b4.ns_jft_in1k\" : ['evidental', \"progressive_evidental\"]\n",
    "# }\n",
    "\n",
    "# Default classifier for models not in the map\n",
    "# DEFAULT_CLASSIFIER = 'baseline'\n",
    "\n",
    "# print(\"Classifier Configuration:\")\n",
    "# print(f\"  Default: {DEFAULT_CLASSIFIER}\")\n",
    "# print(f\"  Custom mappings: {len(MODEL_CLASSIFIER_MAP)}\")\n",
    "# for model, clf in MODEL_CLASSIFIER_MAP.items():\n",
    "#     print(f\"    {model}: {clf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('.')))\n",
    "try:\n",
    "    from module.config import SUBPROCESS_TIMEOUT\n",
    "    print(f\"Loaded timeout: {SUBPROCESS_TIMEOUT}s ({SUBPROCESS_TIMEOUT/3600:.1f}h)\")\n",
    "except ImportError:\n",
    "    SUBPROCESS_TIMEOUT = 12 * 3600\n",
    "    print(f\"Default timeout: {SUBPROCESS_TIMEOUT}s ({SUBPROCESS_TIMEOUT/3600:.1f}h)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subprocess_template",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBPROCESS_TEMPLATE = r\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import logging\n",
    "import shutil\n",
    "import torch\n",
    "import timm\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    cohen_kappa_score, matthews_corrcoef, jaccard_score,\n",
    ")\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import time\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import sys\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Directory structure\n",
    "OUTPUT_DIR = \"output\"\n",
    "RESULTS_DIR = os.path.join(OUTPUT_DIR, \"results\")\n",
    "PLOTS_DIR = os.path.join(RESULTS_DIR, \"plots\")\n",
    "REPORTS_DIR = os.path.join(RESULTS_DIR, \"reports\")\n",
    "LOG_DIR = os.path.join(OUTPUT_DIR, \"logs\")\n",
    "DATA_DIR = \"OriginalDataset\"\n",
    "\n",
    "# Classifier Configuration\n",
    "OPTIMIZE_METRIC = 'recall'  # Primary metric: 'recall', 'accuracy', 'f1', 'precision'\n",
    "MIN_DELTA_METRIC = 0.001  # Minimum improvement threshold for early stopping\n",
    "\n",
    "# Training hyperparameters\n",
    "EPOCHS = 30  # Total epochs (will be distributed in progressive training)\n",
    "NFOLDS = 5\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "PRETRAINED = True\n",
    "NUM_SAMPLES_TO_ANALYSE = 5  # For GradCAM/XAI visualization\n",
    "TEST_SPLIT = 0.2\n",
    "PATIENCE = 10\n",
    "MIN_DELTA = 0.3  # For legacy compatibility\n",
    "LR = 1e-4\n",
    "\n",
    "# Optimization settings\n",
    "USE_AMP = True  # Automatic Mixed Precision\n",
    "PIN_MEMORY = True\n",
    "PERSISTENT_WORKERS = True\n",
    "\n",
    "# Memory management\n",
    "EMPTY_CACHE_FREQUENCY = 1\n",
    "SAVE_BEST_ONLY = True\n",
    "\n",
    "# Timeout settings (in seconds)\n",
    "SUBPROCESS_TIMEOUT = 8 * 3600\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "RECOMMENDED_IMG_SIZES = {\n",
    "    \"tf_efficientnet_b4\": 380, \n",
    "    \"tf_efficientnetv2_s\": 300, \n",
    "    \"inception_v3\": 299, \n",
    "    \"xception\": 299,\n",
    "    \"vit_base_patch16_224\": 224, \n",
    "    \"swin_base_patch4_window7_224\": 224, \n",
    "    \"convnext_small\": 224,\n",
    "    \"convnext_tiny\": 224, \n",
    "    \"maxvit_tiny_224\": 224, \n",
    "    \"resnet50\": 224, \n",
    "    \"resnext50_32x4d\": 224,\n",
    "    \"densenet121\": 224, \n",
    "    \"coatnet_0_rw_224\": 224, \n",
    "    \"resnet18\": 224, \n",
    "    \"vgg16_bn\": 224, \n",
    "    \"efficientnet_b0\": 224,\n",
    "    \"mobilenetv3_large_100\": 224, \n",
    "    \"vit_tiny_patch16_224\": 224, \n",
    "    \"poolformer_s12\": 224,\n",
    "    \"efficientformer_l1\": 224,\n",
    "    \"mobilevit_s\": 224,\n",
    "    \"ghostnet_100\": 224\n",
    "}\n",
    "\n",
    "\n",
    "def get_img_size(model_name):\n",
    "    base_name = model_name.split(\".\")[0]\n",
    "    return RECOMMENDED_IMG_SIZES.get(base_name, 224)\n",
    "\n",
    "\n",
    "def get_model(model_name, num_classes, pretrained=True):\n",
    "    try:\n",
    "        model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "        \n",
    "        # Disable auxiliary classifier for Inception v3 during training\n",
    "        if \"inception\" in model_name and pretrained:\n",
    "            model.aux_logits = False\n",
    "            \n",
    "        print(f\"Loaded model: {model_name} | Pretrained: {pretrained} | Classes: {num_classes}\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model '{model_name}': {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "class FullDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        from torchvision.datasets import ImageFolder\n",
    "        self.transform = transform\n",
    "        data = ImageFolder(root=data_dir)\n",
    "        self.samples = data.samples\n",
    "        self.targets = data.targets\n",
    "        self.classes = data.classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, name: str = \"Logger\", file_name: str = \"batch\"):\n",
    "        self.logger = logging.getLogger(name)\n",
    "        self.current_log_dir = os.path.join(LOG_DIR, name)\n",
    "        os.makedirs(self.current_log_dir, exist_ok=True)\n",
    "        \n",
    "        if not self.logger.handlers:\n",
    "            self.logger.setLevel(logging.DEBUG)\n",
    "            \n",
    "            formatter = logging.Formatter(\"[%(levelname)s] %(asctime)s - %(name)s - %(message)s\")\n",
    "            console_formatter = logging.Formatter(\"[%(name)s] %(message)s\")\n",
    "\n",
    "            base_file_name = os.path.join(self.current_log_dir, file_name)\n",
    "\n",
    "            info_path = f\"{base_file_name}_debug.log\"\n",
    "            info_handler = logging.FileHandler(info_path, encoding=\"utf-8\")\n",
    "            info_handler.setLevel(logging.DEBUG)\n",
    "            info_handler.setFormatter(formatter)\n",
    "            \n",
    "            error_path = f\"{base_file_name}_error.log\"\n",
    "            error_handler = logging.FileHandler(error_path)\n",
    "            error_handler.setLevel(logging.ERROR)\n",
    "            error_handler.setFormatter(formatter)\n",
    "            \n",
    "            console_handler = logging.StreamHandler()\n",
    "            console_handler.setLevel(logging.INFO)\n",
    "            console_handler.setFormatter(console_formatter)\n",
    "\n",
    "            self.logger.addHandler(info_handler)\n",
    "            self.logger.addHandler(error_handler)\n",
    "            self.logger.addHandler(console_handler)\n",
    "\n",
    "    def info(self, message: str) -> None:\n",
    "        self.logger.info(message)\n",
    "\n",
    "    def warning(self, message: str) -> None:\n",
    "        self.logger.warning(message)\n",
    "\n",
    "    def error(self, message: str, exc_info : bool = True) -> None:\n",
    "        self.logger.error(message, exc_info)\n",
    "    \n",
    "    def debug(self, message: str) -> None:\n",
    "        self.logger.debug(message)\n",
    "\n",
    "\n",
    "# Sharpness-Aware Minimization (SAM)\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    \n",
    "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
    "        if isinstance(params, (list, tuple)) and isinstance(params[0], dict):\n",
    "            param_groups = params\n",
    "        else:\n",
    "            param_groups = [{'params': params}]\n",
    "\n",
    "        defaults = dict(rho=rho, **kwargs)\n",
    "        super().__init__(param_groups, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "            \n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None :\n",
    "                    continue\n",
    "                # Save current weights\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                # Ascent step\n",
    "                e_w = p.grad * scale.to(p)\n",
    "                p.add_(e_w)\n",
    "        \n",
    "        if zero_grad :\n",
    "            self.zero_grad()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None :\n",
    "                    continue\n",
    "                # Restore original weights\n",
    "                p.data = self.state[p][\"old_p\"]\n",
    "        \n",
    "        # Now take actual optimizer step with new gradient\n",
    "        self.base_optimizer.step()\n",
    "        \n",
    "        if zero_grad :\n",
    "            self.zero_grad()\n",
    "    \n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device\n",
    "        norm = torch.norm(\n",
    "            torch.stack([\n",
    "                p.grad.norm(p=2).to(shared_device)\n",
    "                for group in self.param_groups for p in group[\"params\"]\n",
    "                if p.grad is not None\n",
    "            ]),\n",
    "            p=2\n",
    "        )\n",
    "        return norm\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, scaler, gpu_augmenter=None, scheduler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in loader :\n",
    "        images, labels = images.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
    "        \n",
    "        if gpu_augmenter:\n",
    "            images = gpu_augmenter(images)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        if isinstance(optimizer, SAM) :\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.first_step(zero_grad = True)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.second_step(zero_grad = True)\n",
    "        else :\n",
    "            with torch.amp.autocast(device_type = DEVICE, dtype=torch.float16, enabled=(DEVICE == 'cuda')):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        if scheduler and isinstance(scheduler, (\n",
    "                    optim.lr_scheduler.OneCycleLR,\n",
    "                    optim.lr_scheduler.SequentialLR\n",
    "                )):\n",
    "            scheduler.step()\n",
    "\n",
    "        running_loss += loss.detach().item() * images.size(0)\n",
    "        \n",
    "        _, predicted = outputs.detach().max(1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    total_loss = running_loss / len(loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds) * 100.0\n",
    "    \n",
    "    return total_loss, acc\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for images, labels in loader :\n",
    "            images, labels = images.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
    "            \n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(DEVICE == 'cuda')):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    total_loss = running_loss / len(loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds) * 100.0\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    return total_loss, acc, prec, rec, f1\n",
    "\n",
    "\n",
    "def get_base_transformations(img_size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "def _aggressive_empty_directory(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        return\n",
    "\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "\n",
    "        if (os.path.isfile(item_path) or os.path.islink(item_path)) and not item.endswith(\".zip\"):\n",
    "            os.remove(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            try:\n",
    "                shutil.rmtree(item_path)\n",
    "            except Exception:\n",
    "                _aggressive_empty_directory(item_path)\n",
    "                try:\n",
    "                    os.rmdir(item_path)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "def zip_and_empty(source_dir, output_zip):\n",
    "    import zipfile\n",
    "    \n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"Directory '{source_dir}' does not exist. Skipping.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üì¶ Zipping '{source_dir}' to '{output_zip}'...\")\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for root, dirs, files in os.walk(source_dir):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    parent_dir = os.path.dirname(source_dir)\n",
    "                    arcname = os.path.relpath(file_path, parent_dir)\n",
    "                    zipf.write(file_path, arcname=arcname)\n",
    "                    \n",
    "        if os.path.exists(output_zip):\n",
    "            print(f\"‚úÖ Zip created successfully: {output_zip}\")\n",
    "            print(f\"üóëÔ∏è Emptying target folder: {source_dir}\")\n",
    "            _aggressive_empty_directory(source_dir)\n",
    "            print(\"‚úÖ Cleanup complete.\")\n",
    "        else:\n",
    "            print(\"‚ùå Zip creation failed. Folder NOT emptied.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred during process: {e}\")\n",
    "\n",
    "\n",
    "def reshape_transform_swin(tensor, height=7, width=7):\n",
    "    result = tensor.reshape(tensor.size(0), height, width, tensor.size(2))\n",
    "    result = result.permute(0, 3, 1, 2)\n",
    "    return result\n",
    "\n",
    "class NativeGradCAM:\n",
    "    def __init__(self, model, target_layer, reshape_transform=None):\n",
    "        self.model = model.eval()\n",
    "        self.reshape_transform = reshape_transform\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "        self.hooks = []\n",
    "        \n",
    "        self.hooks.append(target_layer.register_forward_hook(self.save_activation))\n",
    "        self.hooks.append(target_layer.register_full_backward_hook(self.save_gradient))\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        # Clone to avoid inplace modification issues\n",
    "        self.activations = output.clone() if isinstance(output, torch.Tensor) else output\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        # Clone to avoid inplace modification issues\n",
    "        self.gradients = grad_output[0].clone() if isinstance(grad_output[0], torch.Tensor) else grad_output[0]\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Ensure model is in eval mode and disable inplace operations\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.enable_grad():\n",
    "            input_tensor = input_tensor.clone().detach().requires_grad_(True)\n",
    "            output = self.model(input_tensor)\n",
    "            pred_index = output.argmax(dim=1)\n",
    "            score = output[:, pred_index]\n",
    "            score.backward()\n",
    "        \n",
    "        grads = self.gradients\n",
    "        fmaps = self.activations\n",
    "        \n",
    "        if self.reshape_transform:\n",
    "            grads = self.reshape_transform(grads)\n",
    "            fmaps = self.reshape_transform(fmaps)\n",
    "        \n",
    "        weights = torch.mean(grads, dim=(2, 3), keepdim=True)\n",
    "        cam = torch.sum(weights * fmaps, dim=1, keepdim=True)\n",
    "        cam = F.relu(cam)\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-7)\n",
    "        \n",
    "        return cam.detach().cpu().numpy()[0, 0]\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "\n",
    "\n",
    "def generate_gradcam_plot(model, input_tensor, original_img_np, target_layer, reshape_transform=None, alpha=0.4):\n",
    "    cam_engine = NativeGradCAM(model, target_layer, reshape_transform)\n",
    "    \n",
    "    try:\n",
    "        import cv2\n",
    "        heatmap = cam_engine(input_tensor)\n",
    "        heatmap = cv2.resize(heatmap, (original_img_np.shape[1], original_img_np.shape[0]))\n",
    "        heatmap_uint8 = np.uint8(255 * heatmap)\n",
    "        heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
    "        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if original_img_np.max() <= 1.0:\n",
    "            original_img_np = np.uint8(255 * original_img_np)\n",
    "        else:\n",
    "            original_img_np = np.uint8(original_img_np)\n",
    "        \n",
    "        superimposed_img = cv2.addWeighted(original_img_np, 1, heatmap_colored, alpha, 0)\n",
    "        return superimposed_img\n",
    "        \n",
    "    finally:\n",
    "        cam_engine.remove_hooks()\n",
    "\n",
    "\n",
    "class Visualizer:\n",
    "    \n",
    "    def __init__(self, experiment_name, model_name, class_names, transform=None, logger=None):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model_name = model_name\n",
    "        self.class_names = class_names\n",
    "        self.logger = logger\n",
    "        self.img_size = get_img_size(model_name)\n",
    "        self.transform = transform or get_base_transformations(self.img_size)\n",
    "        \n",
    "        self.save_dir = os.path.join(PLOTS_DIR, experiment_name)\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def log(self, msg):\n",
    "        if self.logger:\n",
    "            self.logger.info(msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "\n",
    "    # =========================================================================\n",
    "    # Plots\n",
    "    # =========================================================================\n",
    "    def plot_training_history(self, history):\n",
    "        if not history:\n",
    "            return\n",
    "\n",
    "        epochs = [h['epoch'] + 1 for h in history]\n",
    "        metrics = ['loss', 'acc', 'f1', 'prec', 'rec']\n",
    "        titles = ['Cross Entropy Loss', 'Accuracy (%)', 'F1 Score', 'Precision', 'Recall']\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        fig.suptitle(f\"Training Dynamics: {self.experiment_name}\", fontsize=16, weight='bold')\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            ax = axes[i]\n",
    "            train_key = f'train_{metric}'\n",
    "            val_key = f'val_{metric}'\n",
    "            \n",
    "            if train_key in history[0]:\n",
    "                train_vals = [h[train_key] for h in history]\n",
    "                ax.plot(epochs, train_vals, 'o--', label='Train', color='cornflowerblue', linewidth=2)\n",
    "            \n",
    "            if val_key in history[0]:\n",
    "                val_vals = [h[val_key] for h in history]\n",
    "                ax.plot(epochs, val_vals, 'o-', label='Validation', color='darkorange', linewidth=2)\n",
    "            \n",
    "            ax.set_title(titles[i])\n",
    "            ax.set_xlabel(\"Epochs\")\n",
    "            ax.grid(True, linestyle='--', alpha=0.6)\n",
    "            ax.legend()\n",
    "\n",
    "        axes[-1].axis('off')\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        \n",
    "        save_path = os.path.join(self.save_dir, \"training_history.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred, normalize=False):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        fmt = 'd'\n",
    "        \n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            fmt = '.2f'\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues', \n",
    "                    xticklabels=self.class_names, yticklabels=self.class_names,\n",
    "                    square=True, cbar_kws={\"shrink\": .8})\n",
    "        plt.ylabel('True Label', fontsize=12)\n",
    "        plt.xlabel('Predicted Label', fontsize=12)\n",
    "        plt.title(f'Confusion Matrix: {self.experiment_name}', fontsize=14)\n",
    "        \n",
    "        save_path = os.path.join(self.save_dir, \"confusion_matrix.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def plot_classwise_metrics(self, y_true, y_pred):\n",
    "        report = classification_report(y_true, y_pred, target_names=self.class_names, output_dict=True)\n",
    "        \n",
    "        metrics_list = []\n",
    "        for cls in self.class_names:\n",
    "            if cls in report:\n",
    "                metrics_list.append({\n",
    "                    'Class': cls,\n",
    "                    'Precision': report[cls]['precision'],\n",
    "                    'Recall': report[cls]['recall'],\n",
    "                    'F1-Score': report[cls]['f1-score']\n",
    "                })\n",
    "            else:\n",
    "                self.logger.error(f\"Class {cls} not found in classification report\\n{report}\")\n",
    "        \n",
    "        if not metrics_list:\n",
    "            raise ValueError(\"No valid class metrics found\")\n",
    "        \n",
    "        df = pd.DataFrame(metrics_list).set_index('Class')\n",
    "        \n",
    "        plt.figure(figsize=(8, len(self.class_names) * 0.8 + 2))\n",
    "        sns.heatmap(df, annot=True, cmap='RdYlGn', fmt='.3f', vmin=0.0, vmax=1.0, linewidths=1)\n",
    "        plt.title('Class-wise Performance Metrics', fontsize=14)\n",
    "        plt.yticks(rotation=0)\n",
    "        \n",
    "        save_path = os.path.join(self.save_dir, \"classwise_metrics.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def plot_roc_curve(self, y_true, y_prob):\n",
    "        n_classes = len(self.class_names)\n",
    "        y_true_bin = pd.get_dummies(y_true).values\n",
    "        \n",
    "        # Check for NaN in y_prob\n",
    "        if np.isnan(y_prob).any():\n",
    "            self.log(f\"‚ö†Ô∏è  Warning: NaN values detected in predictions. Replacing with 0.25 (1/n_classes)\")\n",
    "            y_prob = np.nan_to_num(y_prob, nan=1.0/n_classes)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple'])\n",
    "\n",
    "        classes_plotted = 0\n",
    "        \n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            if i < y_prob.shape[1]:\n",
    "                try:\n",
    "                    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
    "                    auc_score = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, \n",
    "                             label=f'ROC of {self.class_names[i]} (AUC = {auc_score:0.2f})')\n",
    "                    classes_plotted += 1\n",
    "                except Exception as e:\n",
    "                    self.log(f\"‚ö†Ô∏è  Skipping ROC for {self.class_names[i]}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if classes_plotted == 0 :\n",
    "            raise ValueError(\"No ROC curve plotted for any of the classes\")\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curves: {self.experiment_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        save_path = os.path.join(self.save_dir, \"roc_curve.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def plot_precision_recall_curve(self, y_true, y_prob):\n",
    "        n_classes = len(self.class_names)\n",
    "        y_true_bin = pd.get_dummies(y_true).values\n",
    "        \n",
    "        # Check for NaN in y_prob\n",
    "        if np.isnan(y_prob).any():\n",
    "            self.log(f\"‚ö†Ô∏è  Warning: NaN values detected in predictions. Replacing with 0.25 (1/n_classes)\")\n",
    "            y_prob = np.nan_to_num(y_prob, nan=1.0/n_classes)\n",
    "    \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple'])\n",
    "        \n",
    "        classes_plotted = 0\n",
    "        \n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            if i < y_prob.shape[1]:\n",
    "                try:\n",
    "                    prec, rec, _ = precision_recall_curve(y_true_bin[:, i], y_prob[:, i])\n",
    "                    avg_prec = average_precision_score(y_true_bin[:, i], y_prob[:, i])\n",
    "                    plt.plot(rec, prec, color=color, lw=2, \n",
    "                             label=f'{self.class_names[i]} (AP = {avg_prec:0.2f})')\n",
    "                    classes_plotted += 1\n",
    "                except Exception as e:\n",
    "                    self.log(f\"‚ö†Ô∏è  Skipping PR curve for {self.class_names[i]}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if classes_plotted == 0 :\n",
    "            raise ValueError(\"No PR curve plotted for any of the classes\")\n",
    "        \n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title(f'Precision-Recall Curves: {self.experiment_name}')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(os.path.join(self.save_dir, \"precision_recall_curve.png\"), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_confidence_distribution(self, y_true, y_prob):\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        confidences = np.max(y_prob, axis=1).astype(np.float32)  # Convert to float32\n",
    "        \n",
    "        correct_mask = (y_pred == y_true)\n",
    "        incorrect_mask = ~correct_mask\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        sns.histplot(confidences[correct_mask], color='green', label='Correct Predictions', \n",
    "                     kde=True, bins=20, alpha=0.5, element=\"step\")\n",
    "        \n",
    "        if np.any(incorrect_mask):\n",
    "            sns.histplot(confidences[incorrect_mask], color='red', label='Incorrect Predictions', \n",
    "                         kde=True, bins=20, alpha=0.5, element=\"step\")\n",
    "            \n",
    "        plt.xlabel(\"Prediction Confidence (Probability)\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(f\"Confidence Distribution{' : Correct vs Incorrect' if np.any(incorrect_mask) else ''}\")\n",
    "        plt.legend()\n",
    "        \n",
    "        save_path = os.path.join(self.save_dir, \"confidence_analysis.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def plot_cumulative_gain(self, y_true, y_prob):\n",
    "        n_classes = y_prob.shape[1]\n",
    "        y_true_bin = pd.get_dummies(y_true).values\n",
    "        percentages = np.arange(1, len(y_true) + 1) / len(y_true)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot([0, 1], [0, 1], 'k--', label=\"Random Model\")\n",
    "\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple'])\n",
    "\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            score = y_prob[:, i]\n",
    "            true_class = y_true_bin[:, i]\n",
    "\n",
    "            order = np.argsort(score)[::-1]\n",
    "            true_sorted = true_class[order]\n",
    "            cum_gains = np.cumsum(true_sorted)\n",
    "            \n",
    "            total_positives = np.sum(true_class)\n",
    "            if total_positives > 0:\n",
    "                cum_gains = cum_gains / total_positives\n",
    "            else:\n",
    "                cum_gains = np.zeros_like(cum_gains)\n",
    "\n",
    "            plt.plot(percentages, cum_gains, color=color, lw=2, label=f'{self.class_names[i]}')\n",
    "\n",
    "        plt.xlabel(\"Percentage of Sample Targeted\")\n",
    "        plt.ylabel(\"Cumulative Gain\")\n",
    "        plt.title(f\"Cumulative Gain Curve: {self.experiment_name}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        save_path = os.path.join(self.save_dir, \"cumulative_gain.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # =========================================================================\n",
    "    # XAI\n",
    "    # =========================================================================\n",
    "    def _get_target_layer(self, model):\n",
    "        try:\n",
    "            if \"swin\" in self.model_name:\n",
    "                return model.layers[-1].blocks[-1].norm2\n",
    "            elif \"resnet\" in self.model_name or \"resnext\" in self.model_name:\n",
    "                return model.layer4[-1]\n",
    "            elif \"efficientnet\" in self.model_name:\n",
    "                return model.conv_head\n",
    "            elif \"densenet\" in self.model_name:\n",
    "                return model.features.norm5\n",
    "            elif \"convnext\" in self.model_name:\n",
    "                return model.stages[-1].blocks[-1].norm\n",
    "            elif \"mobilenet\" in self.model_name:\n",
    "                # MobileNet has special handling for inplace operations\n",
    "                return model.conv_head\n",
    "            else:\n",
    "                # Recursive fallback to last Conv2d\n",
    "                for name, module in list(model.named_modules())[::-1]:\n",
    "                    if isinstance(module, torch.nn.Conv2d):\n",
    "                        return module\n",
    "        except Exception as e:\n",
    "            if self.logger:\n",
    "                self.logger.error(f\"Error determining target layer: {e}\")\n",
    "        return None\n",
    "\n",
    "    def run_grad_cam(self, model, image_path, target_layer):\n",
    "        # Disable inplace operations for models like MobileNetV3\n",
    "        def set_inplace_false(m):\n",
    "            for attr in dir(m):\n",
    "                if 'inplace' in attr:\n",
    "                    try:\n",
    "                        setattr(m, attr, False)\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        model.apply(set_inplace_false)\n",
    "        model.eval()\n",
    "        \n",
    "        pil_img = Image.open(image_path).convert('RGB').resize((self.img_size, self.img_size))\n",
    "        input_tensor = self.transform(pil_img).unsqueeze(0).to(DEVICE)\n",
    "        original_img_np = np.array(pil_img)\n",
    "        \n",
    "        reshape = reshape_transform_swin if \"swin\" in str(type(model)).lower() else None\n",
    "        viz_img = generate_gradcam_plot(model, input_tensor, original_img_np, target_layer, reshape)\n",
    "        return viz_img\n",
    "\n",
    "    def run_lime(self, model, image_path):\n",
    "        from lime import lime_image\n",
    "        from skimage.segmentation import mark_boundaries\n",
    "        \n",
    "        def batch_predict(images):\n",
    "            pil_images = [Image.fromarray(img.astype('uint8')) for img in images]\n",
    "            batch = torch.stack([self.transform(img) for img in pil_images], dim=0).to(DEVICE)\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                model.eval()\n",
    "                with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(DEVICE == 'cuda')):\n",
    "                    logits = model(batch)\n",
    "                probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "                \n",
    "                # Handle NaN in predictions\n",
    "                if np.isnan(probs).any():\n",
    "                    n_classes = probs.shape[1]\n",
    "                    probs = np.nan_to_num(probs, nan=1.0/n_classes)\n",
    "                    # Normalize to ensure sum=1\n",
    "                    probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "                \n",
    "                return probs\n",
    "        \n",
    "        image_np = np.array(Image.open(image_path).convert('RGB').resize((self.img_size, self.img_size)))\n",
    "        explainer = lime_image.LimeImageExplainer()\n",
    "        \n",
    "        explanation = explainer.explain_instance(\n",
    "            image_np, \n",
    "            batch_predict, \n",
    "            top_labels=1, \n",
    "            hide_color=0, \n",
    "            num_samples=300\n",
    "        )\n",
    "        \n",
    "        temp, mask = explanation.get_image_and_mask(\n",
    "            explanation.top_labels[0], \n",
    "            positive_only=True, \n",
    "            num_features=5, \n",
    "            hide_rest=False\n",
    "        )\n",
    "        \n",
    "        lime_viz = mark_boundaries(temp / 255.0, mask)\n",
    "        return (np.clip(lime_viz, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "    def run_shap(self, model, image_path):\n",
    "        import shap\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB').resize((self.img_size, self.img_size))\n",
    "        input_tensor = self.transform(image).unsqueeze(0).to(DEVICE)\n",
    "        background = torch.randn(5, 3, self.img_size, self.img_size).to(DEVICE)\n",
    "        \n",
    "        explainer = shap.GradientExplainer(model, background)\n",
    "        shap_values = explainer.shap_values(input_tensor)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            output = model(input_tensor)\n",
    "            pred_idx = torch.argmax(output).item()\n",
    "        \n",
    "        shap_numpy = np.swapaxes(np.swapaxes(shap_values[pred_idx], 1, -1), 1, 2)\n",
    "        input_numpy = np.swapaxes(np.swapaxes(input_tensor.cpu().numpy(), 1, -1), 1, 2)\n",
    "        \n",
    "        temp_filename = f\"temp_shap_{os.getpid()}_{np.random.randint(10000)}.png\"\n",
    "        \n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        shap.image_plot(shap_numpy, -input_numpy, show=False)\n",
    "        plt.savefig(temp_filename, bbox_inches='tight', pad_inches=0, dpi=100)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        if os.path.exists(temp_filename):\n",
    "            shap_img = np.array(Image.open(temp_filename).convert('RGB'))\n",
    "            os.remove(temp_filename)\n",
    "            return shap_img\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"SHAP temp file not created\")\n",
    "\n",
    "    def generate_xai_comparison_plot(self, model, image_path, sample_id):\n",
    "        model.eval()\n",
    "        \n",
    "        original_img = np.array(Image.open(image_path).convert('RGB').resize((self.img_size, self.img_size)))\n",
    "        image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        self.log(f\"  Generating XAI comparison for {image_basename}...\")\n",
    "        \n",
    "        target_layer = self._get_target_layer(model)\n",
    "        \n",
    "        # Try each XAI method independently\n",
    "        xai_results = {}\n",
    "        \n",
    "        # GradCAM\n",
    "        if target_layer is not None:\n",
    "            try:\n",
    "                xai_results['gradcam'] = self.run_grad_cam(model, image_path, target_layer)\n",
    "            except Exception as e:\n",
    "                if self.logger:\n",
    "                    self.logger.error(f\"GradCAM failed for {image_path}: {e}\")\n",
    "                xai_results['gradcam'] = None\n",
    "        \n",
    "        # LIME\n",
    "        try:\n",
    "            xai_results['lime'] = self.run_lime(model, image_path)\n",
    "        except Exception as e:\n",
    "            if self.logger:\n",
    "                self.logger.error(f\"LIME failed for {image_path}: {e}\")\n",
    "            xai_results['lime'] = None\n",
    "        \n",
    "        # SHAP\n",
    "        try:\n",
    "            xai_results['shap'] = self.run_shap(model, image_path)\n",
    "        except Exception as e:\n",
    "            if self.logger:\n",
    "                self.logger.error(f\"SHAP failed for {image_path}: {e}\")\n",
    "            xai_results['shap'] = None\n",
    "        \n",
    "        successful_methods = sum(1 for v in xai_results.values() if v is not None)\n",
    "        \n",
    "        # If all methods failed, skip plot\n",
    "        if successful_methods == 0:\n",
    "            self.log(f\"  ‚úó All XAI methods failed for {sample_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Create 2x2 comparison plot\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle(f\"XAI Comparison: {os.path.basename(image_path)} ({self.model_name})\", fontsize=16, weight='bold')\n",
    "        \n",
    "        # [0,0] Original (top-left)\n",
    "        axes[0, 0].imshow(original_img)\n",
    "        axes[0, 0].set_title(\"Original\", fontsize=14, color='black')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # [0,1] GradCAM (top-right)\n",
    "        if xai_results['gradcam'] is not None:\n",
    "            axes[0, 1].imshow(xai_results['gradcam'])\n",
    "            axes[0, 1].set_title(\"GradCAM\", fontsize=14, color='green')\n",
    "        else:\n",
    "            axes[0, 1].text(0.5, 0.5, \"GradCAM\\n(Failed)\", ha='center', va='center', \n",
    "                           fontsize=16, color='red', weight='bold',\n",
    "                           transform=axes[0, 1].transAxes)\n",
    "            axes[0, 1].set_facecolor('#ffcccc')\n",
    "            axes[0, 1].set_title(\"GradCAM\", fontsize=14, color='red')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # [1,0] LIME (bottom-left)\n",
    "        if xai_results['lime'] is not None:\n",
    "            axes[1, 0].imshow(xai_results['lime'])\n",
    "            axes[1, 0].set_title(\"LIME\", fontsize=14, color='green')\n",
    "        else:\n",
    "            axes[1, 0].text(0.5, 0.5, \"LIME\\n(Failed)\", ha='center', va='center',\n",
    "                           fontsize=16, color='red', weight='bold',\n",
    "                           transform=axes[1, 0].transAxes)\n",
    "            axes[1, 0].set_facecolor('#ffcccc')\n",
    "            axes[1, 0].set_title(\"LIME\", fontsize=14, color='red')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # [1,1] SHAP (bottom-right)\n",
    "        if xai_results['shap'] is not None:\n",
    "            axes[1, 1].imshow(xai_results['shap'])\n",
    "            axes[1, 1].set_title(\"SHAP\", fontsize=14, color='green')\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, \"SHAP\\n(Failed)\", ha='center', va='center',\n",
    "                           fontsize=16, color='red', weight='bold',\n",
    "                           transform=axes[1, 1].transAxes)\n",
    "            axes[1, 1].set_facecolor('#ffcccc')\n",
    "            axes[1, 1].set_title(\"SHAP\", fontsize=14, color='red')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        # 6. Save\n",
    "        image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        output_filename = os.path.join(self.save_dir, f\"xai_comparison_{sample_id}_{image_basename}.png\")\n",
    "        plt.savefig(output_filename, bbox_inches='tight', dpi=150)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        return output_filename, successful_methods\n",
    "\n",
    "    # =========================================================================\n",
    "    # 4. MASTER GENERATOR\n",
    "    # =========================================================================\n",
    "    def generate_all_plots(self, y_true, y_prob, history=None, model=None, test_loader=None, xai_samples=5):\n",
    "        self.log(f\"Generating visualizations for {self.experiment_name}...\")\n",
    "        \n",
    "        # Check for NaN in y_prob at the start\n",
    "        if np.isnan(y_prob).any():\n",
    "            self.log(f\"‚ö†Ô∏è  WARNING: NaN detected in probability outputs! Model may have collapsed.\")\n",
    "            self.log(f\"   This usually happens when the model predicts only one class.\")\n",
    "            self.log(f\"   Replacing NaN with uniform distribution (1/n_classes) for visualization.\")\n",
    "        \n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        \n",
    "        # Results tracking\n",
    "        results = {\n",
    "            'xai_success': 0,\n",
    "            'xai_total': 0,\n",
    "            'plots': {}\n",
    "        }\n",
    "\n",
    "        # XAI Analysis\n",
    "        if model and test_loader and xai_samples > 0:\n",
    "            self.log(f\"Generating XAI comparisons for {xai_samples} samples...\")\n",
    "            \n",
    "            dataset = test_loader.dataset\n",
    "            full_ds = dataset.dataset if hasattr(dataset, 'dataset') else dataset\n",
    "            \n",
    "            if hasattr(full_ds, 'samples'):\n",
    "                indices = np.random.choice(len(dataset), min(xai_samples, len(dataset)), replace=False)\n",
    "                \n",
    "                for i, idx in enumerate(indices):\n",
    "                    img_path = full_ds.samples[idx][0]\n",
    "                    image_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "                    \n",
    "                    self.log(f\"  Generating XAI comparison for {image_name}...\")\n",
    "                    results['xai_total'] += 1\n",
    "                    \n",
    "                    try:\n",
    "                        result = self.generate_xai_comparison_plot(model, img_path, sample_id=f\"sample_{i}\")\n",
    "                        if result is not None:\n",
    "                            output_file, success_count = result\n",
    "                            results['xai_success'] += 1\n",
    "                            self.log(f\"    ‚úì XAI comparison saved ({success_count}/3 methods successful)\")\n",
    "                        else:\n",
    "                            self.log(f\"    ‚úó XAI comparison failed (all methods failed)\")\n",
    "                    except Exception as e:\n",
    "                        self.log(f\"    ‚úó XAI comparison failed: {e}\")\n",
    "                        if self.logger:\n",
    "                            self.logger.error(f\"XAI error for {img_path}: {e}\", exc_info=True)\n",
    "        \n",
    "        # Clean up model from memory\n",
    "        try:\n",
    "            import gc\n",
    "            del model, test_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            self.log(f\"Cleanup failed : {e}\")\n",
    "            if self.logger:\n",
    "                self.logger.error(f\"Cleanup of model and test loader failed : {e}\", exc_info=True)\n",
    "        \n",
    "        plot_functions = [\n",
    "            ('training_history', lambda: self.plot_training_history(history) if history else None),\n",
    "            ('confusion_matrix', lambda: self.plot_confusion_matrix(y_true, y_pred, normalize=True)),\n",
    "            ('classwise_metrics', lambda: self.plot_classwise_metrics(y_true, y_pred)),\n",
    "            ('roc_curve', lambda: self.plot_roc_curve(y_true, y_prob)),\n",
    "            ('precision_recall', lambda: self.plot_precision_recall_curve(y_true, y_prob)),\n",
    "            ('confidence', lambda: self.plot_confidence_distribution(y_true, y_prob)),\n",
    "            ('cumulative_gain', lambda: self.plot_cumulative_gain(y_true, y_prob))\n",
    "        ]\n",
    "        \n",
    "        # Execute each plot with error handling\n",
    "        for plot_name, plot_func in plot_functions:\n",
    "            try:\n",
    "                plot_func()\n",
    "                results['plots'][plot_name] = True\n",
    "                self.log(f\"‚úì {plot_name.replace('_', ' ').title()} saved\")\n",
    "            except Exception as e:\n",
    "                results['plots'][plot_name] = False\n",
    "                self.log(f\"‚úó {plot_name.replace('_', ' ').title()} failed: {e}\")\n",
    "                if self.logger:\n",
    "                    self.logger.error(f\"{plot_name} error: {e}\", exc_info=True)\n",
    "                plt.close('all')\n",
    "        \n",
    "        \n",
    "        # Summary\n",
    "        successful_plots = sum(results['plots'].values())\n",
    "        total_plots = len(results['plots'])\n",
    "        \n",
    "        self.log(f\"‚úÖ Visualization complete: {successful_plots}/{total_plots} plots successful\")\n",
    "        if results['xai_total'] > 0:\n",
    "            self.log(f\"   XAI: {results['xai_success']}/{results['xai_total']} samples\")\n",
    "        self.log(f\"   All outputs saved to {self.save_dir}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "class BaseClassifier(ABC):\n",
    "    \n",
    "    def __init__(self, model_name: str, num_classes: int = 4, device: str = 'cuda', checkpoint_path : str = None):\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        # checkpoint_path: Path to store checkpoints (best model weights)\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "\n",
    "        \n",
    "        # Model (built by subclass)\n",
    "        self.model = None\n",
    "        \n",
    "        # Training state\n",
    "        self.best_metric_value = 0.0\n",
    "        self.best_recall = 0.0\n",
    "        self.best_acc = 0.0\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_epoch = 0\n",
    "        self.history = []\n",
    "        \n",
    "        # Build model\n",
    "        self.build_model()\n",
    "        \n",
    "        if self.model is None:\n",
    "            raise ValueError(\"build_model() must set self.model\")\n",
    "        \n",
    "        self.model = self.model.to(device)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def build_model(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, images: torch.Tensor):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def compute_loss(self, outputs, labels) -> torch.Tensor:\n",
    "        pass\n",
    "    \n",
    "    def get_predictions(self, outputs) -> torch.Tensor:\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "        return torch.argmax(outputs, dim=1)\n",
    "    \n",
    "    def _get_metric_value(self, labels: List, preds: List, metric: str) -> float:\n",
    "        if metric == 'recall':\n",
    "            return recall_score(labels, preds, average='macro', zero_division=0)\n",
    "        elif metric == 'accuracy':\n",
    "            return accuracy_score(labels, preds) * 100\n",
    "        elif metric == 'f1':\n",
    "            return f1_score(labels, preds, average='macro', zero_division=0)\n",
    "        elif metric == 'precision':\n",
    "            return precision_score(labels, preds, average='macro', zero_division=0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {metric}\")\n",
    "    \n",
    "    def train_epoch(self, train_loader, optimizer, scaler=None, scheduler=None):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        # Check if SAM optimizer\n",
    "        from .techniques import SAM\n",
    "        is_sam = isinstance(optimizer, SAM)\n",
    "        use_amp = not is_sam and self.device == 'cuda'\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if is_sam:\n",
    "                # SAM: Two-step (no AMP)\n",
    "                outputs = self.forward(images)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.first_step(zero_grad=True)\n",
    "                \n",
    "                outputs = self.forward(images)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.second_step(zero_grad=True)\n",
    "            else:\n",
    "                # Standard (with AMP if available)\n",
    "                if use_amp and scaler:\n",
    "                    with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                        outputs = self.forward(images)\n",
    "                        loss = self.compute_loss(outputs, labels)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = self.forward(images)\n",
    "                    loss = self.compute_loss(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            # Scheduler step (for OneCycleLR)\n",
    "            if scheduler and isinstance(scheduler, (\n",
    "                optim.lr_scheduler.OneCycleLR,\n",
    "                optim.lr_scheduler.SequentialLR\n",
    "            )):\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Metrics\n",
    "            running_loss += loss.detach().item() * images.size(0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                preds = self.get_predictions(outputs)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "        acc = accuracy_score(all_labels, all_preds) * 100\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        return avg_loss, acc, recall\n",
    "    \n",
    "    def validate_epoch(self, val_loader, primary_metric : str = \"recall\"):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            for images, labels in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.forward(images)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                \n",
    "                preds = self.get_predictions(outputs)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate all metrics\n",
    "        avg_loss = running_loss / len(val_loader.dataset)\n",
    "        acc = accuracy_score(all_labels, all_preds) * 100\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        primary_value = self._get_metric_value(all_labels, all_preds, primary_metric)\n",
    "        \n",
    "        return avg_loss, acc, recall, precision, f1, primary_value\n",
    "    \n",
    "    def fit(self, train_loader, val_loader, epochs: int = 30, \n",
    "            lr: float = 1e-4, use_sam: bool = False,\n",
    "            primary_metric: str = 'recall',\n",
    "            patience: int = 10, min_delta: float = 0.001):\n",
    "        # Optimizer\n",
    "        if use_sam:\n",
    "            from .techniques import SAM\n",
    "            optimizer = SAM(self.model.parameters(), optim.AdamW, lr=lr, weight_decay=0.01, rho=0.05)\n",
    "        else:\n",
    "            optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=0.01)\n",
    "        \n",
    "        # Scheduler\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer.base_optimizer if use_sam else optimizer,\n",
    "            T_max=epochs,\n",
    "            eta_min=1e-7\n",
    "        )\n",
    "        \n",
    "        # Scaler (only if not SAM)\n",
    "        scaler = torch.amp.GradScaler(enabled=(self.device == 'cuda' and not use_sam))\n",
    "        \n",
    "        # Training loop\n",
    "        patience_counter = 0\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training {self.__class__.__name__} - {self.model_name}\")\n",
    "        print(f\"Optimizing for: {primary_metric.upper()} (primary)\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Train\n",
    "            train_loss, train_acc, train_recall = self.train_epoch(\n",
    "                train_loader, optimizer, scaler if not use_sam else None, scheduler\n",
    "            )\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc, val_recall, val_prec, val_f1, primary_value = self.validate_epoch(val_loader)\n",
    "            \n",
    "            # Record history\n",
    "            self.history.append({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'train_acc': train_acc,\n",
    "                'train_recall': train_recall,\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc,\n",
    "                'val_recall': val_recall,\n",
    "                'val_precision': val_prec,\n",
    "                'val_f1': val_f1,\n",
    "                f'val_{primary_metric}': primary_value\n",
    "            })\n",
    "            \n",
    "            # Check improvement\n",
    "            improved = False\n",
    "            improvement_msg = []\n",
    "            \n",
    "            # Primary metric\n",
    "            if primary_value > self.best_metric_value + min_delta:\n",
    "                self.best_metric_value = primary_value\n",
    "                improved = True\n",
    "                improvement_msg.append(f\"{primary_metric.capitalize()}: {primary_value:.4f} ‚òÖ\")\n",
    "            \n",
    "            # Track all metrics\n",
    "            if val_recall > self.best_recall:\n",
    "                self.best_recall = val_recall\n",
    "                if primary_metric != 'recall':\n",
    "                    improvement_msg.append(f\"Recall: {val_recall:.4f}\")\n",
    "            \n",
    "            if val_acc > self.best_acc:\n",
    "                self.best_acc = val_acc\n",
    "                if primary_metric != 'accuracy':\n",
    "                    improvement_msg.append(f\"Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            if val_f1 > self.best_f1:\n",
    "                self.best_f1 = val_f1\n",
    "                if primary_metric != 'f1':\n",
    "                    improvement_msg.append(f\"F1: {val_f1:.4f}\")\n",
    "            \n",
    "            # Print progress\n",
    "            if improved:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - \" + \" | \".join(improvement_msg))\n",
    "                self.best_epoch = epoch + 1\n",
    "                self.save(self.checkpoint_path)\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - {primary_metric}: {primary_value:.4f}, Acc: {val_acc:.2f}%\")\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "            \n",
    "            # Step scheduler\n",
    "            if not isinstance(scheduler, (optim.lr_scheduler.OneCycleLR, optim.lr_scheduler.SequentialLR)):\n",
    "                scheduler.step()\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training Complete!\")\n",
    "        print(f\"Best Epoch: {self.best_epoch}\")\n",
    "        print(f\"Best {primary_metric.capitalize()}: {self.best_metric_value:.4f} ‚òÖ\")\n",
    "        print(f\"Best Recall: {self.best_recall:.4f}\")\n",
    "        print(f\"Best Accuracy: {self.best_acc:.2f}%\")\n",
    "        print(f\"Best F1: {self.best_f1:.4f}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def evaluate(self, test_loader, class_names: Optional[List[str]] = None):\n",
    "        self.model.eval()\n",
    "        all_preds, all_probs, all_labels = [], [], []\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "                images = images.to(self.device)\n",
    "                outputs = self.forward(images)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                preds = self.get_predictions(outputs)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate all metrics\n",
    "        acc = accuracy_score(all_labels, all_preds) * 100\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        # Per-class metrics\n",
    "        if class_names is None:\n",
    "            class_names = [f\"Class {i}\" for i in range(self.num_classes)]\n",
    "        \n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0)\n",
    "        per_class_recall = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "        \n",
    "        # print(f\"\\n{'='*80}\")\n",
    "        # print(f\"TEST RESULTS - {self.__class__.__name__}\")\n",
    "        # print(f\"{'='*80}\")\n",
    "        # print(f\"Overall Accuracy: {acc:.2f}%\")\n",
    "        # print(f\"Overall Recall: {recall:.4f} ‚òÖ (PRIMARY METRIC)\")\n",
    "        # print(f\"Overall Precision: {precision:.4f}\")\n",
    "        # print(f\"Overall F1: {f1:.4f}\")\n",
    "        # print(f\"\\nPer-Class Recall:\")\n",
    "        # for i, (name, rec) in enumerate(zip(class_names, per_class_recall)):\n",
    "        #     print(f\"  {name}: {rec:.4f}\")\n",
    "        # print(f\"\\nConfusion Matrix:\")\n",
    "        # print(cm)\n",
    "        # print(f\"\\nDetailed Report:\")\n",
    "        # print(report)\n",
    "        # print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1,\n",
    "            'per_class_recall': per_class_recall,\n",
    "            'confusion_matrix': cm,\n",
    "            'report': report,\n",
    "            'labels': all_labels,\n",
    "            'preds': all_preds,\n",
    "            'probs': all_probs\n",
    "        }\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "    \n",
    "    def load(self, path: str):\n",
    "        self.model.load_state_dict(torch.load(path, map_location=self.device, weights_only=True))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EVIDENTIAL LAYER\n",
    "# ============================================================================\n",
    "\n",
    "class EvidentialLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.evidence_layer = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        evidence = F.softplus(self.evidence_layer(x))\n",
    "        return evidence\n",
    "    \n",
    "    def get_predictions_and_uncertainty(self, evidence: torch.Tensor) -> Tuple[\n",
    "        torch.Tensor, torch.Tensor, torch.Tensor\n",
    "    ]:\n",
    "        # Dirichlet parameters\n",
    "        alpha = evidence + 1\n",
    "        \n",
    "        # Expected probabilities\n",
    "        S = alpha.sum(dim=1, keepdim=True)\n",
    "        probs = alpha / S\n",
    "        \n",
    "        # Uncertainty (normalized)\n",
    "        K = self.num_classes\n",
    "        uncertainty = K / S\n",
    "        \n",
    "        return probs, uncertainty, alpha\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EVIDENTIAL LOSS\n",
    "# ============================================================================\n",
    "\n",
    "class EvidentialLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes: int, lam: float = 0.5, epsilon: float = 1e-10):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.lam = lam\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def forward(self, evidence: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        alpha = evidence + 1\n",
    "        S = alpha.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        # One-hot encoding\n",
    "        target_one_hot = F.one_hot(target, num_classes=self.num_classes).float()\n",
    "        \n",
    "        # Bayesian risk\n",
    "        A = torch.sum((target_one_hot - alpha / S) ** 2, dim=1, keepdim=True)\n",
    "        B = torch.sum(alpha * (S - alpha) / (S * S * (S + 1)), dim=1, keepdim=True)\n",
    "        loss_mse = (A + B).mean()\n",
    "        \n",
    "        # KL divergence regularization\n",
    "        alpha_tilde = target_one_hot + (1 - target_one_hot) * alpha\n",
    "        S_tilde = alpha_tilde.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        kl_div = torch.lgamma(S_tilde) - torch.lgamma(alpha_tilde).sum(dim=1, keepdim=True)\n",
    "        kl_div += ((alpha_tilde - 1) * (torch.digamma(alpha_tilde) - torch.digamma(S_tilde))).sum(dim=1, keepdim=True)\n",
    "        kl_div = kl_div.mean()\n",
    "        \n",
    "        return loss_mse + self.lam * kl_div\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ARCHITECTURE HANDLER\n",
    "# ============================================================================\n",
    "\n",
    "class ArchitectureHandler:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_feature_extractor(model: nn.Module, model_name: str) -> Tuple[nn.Module, int]:\n",
    "        model_name_lower = model_name.lower()\n",
    "        \n",
    "        # ResNet family\n",
    "        if 'resnet' in model_name_lower or 'resnext' in model_name_lower:\n",
    "            feature_extractor = nn.Sequential(\n",
    "                model.conv1, model.bn1, model.relu, model.maxpool,\n",
    "                model.layer1, model.layer2, model.layer3, model.layer4,\n",
    "                model.global_pool, nn.Flatten()\n",
    "            )\n",
    "            in_features = model.fc.in_features\n",
    "        \n",
    "        # EfficientNet family\n",
    "        elif 'efficientnet' in model_name_lower:\n",
    "            if hasattr(model, 'conv_stem'):\n",
    "                feature_extractor = nn.Sequential(\n",
    "                    model.conv_stem, model.bn1, model.act1,\n",
    "                    model.blocks, model.conv_head, model.bn2, model.act2,\n",
    "                    model.global_pool, nn.Flatten()\n",
    "                )\n",
    "            else:\n",
    "                modules = list(model.children())[:-1]\n",
    "                feature_extractor = nn.Sequential(*modules, nn.Flatten())\n",
    "            \n",
    "            if hasattr(model, 'classifier'):\n",
    "                in_features = model.classifier.in_features\n",
    "            elif hasattr(model, 'fc'):\n",
    "                in_features = model.fc.in_features\n",
    "            else:\n",
    "                dummy = torch.randn(1, 3, 224, 224)\n",
    "                with torch.no_grad():\n",
    "                    out = feature_extractor(dummy)\n",
    "                in_features = out.shape[1]\n",
    "        \n",
    "        # Vision Transformer\n",
    "        elif 'vit' in model_name_lower:\n",
    "            class ViTFeatureExtractor(nn.Module):\n",
    "                def __init__(self, vit_model):\n",
    "                    super().__init__()\n",
    "                    self.patch_embed = vit_model.patch_embed\n",
    "                    self.cls_token = vit_model.cls_token\n",
    "                    self.pos_embed = vit_model.pos_embed\n",
    "                    self.pos_drop = vit_model.pos_drop if hasattr(vit_model, 'pos_drop') else nn.Identity()\n",
    "                    self.blocks = vit_model.blocks\n",
    "                    self.norm = vit_model.norm\n",
    "                \n",
    "                def forward(self, x):\n",
    "                    x = self.patch_embed(x)\n",
    "                    cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "                    x = torch.cat([cls_token, x], dim=1)\n",
    "                    x = x + self.pos_embed\n",
    "                    x = self.pos_drop(x)\n",
    "                    x = self.blocks(x)\n",
    "                    x = self.norm(x)\n",
    "                    return x[:, 0]\n",
    "            \n",
    "            feature_extractor = ViTFeatureExtractor(model)\n",
    "            in_features = model.head.in_features if hasattr(model.head, 'in_features') else model.embed_dim\n",
    "        \n",
    "        # Swin Transformer\n",
    "        elif 'swin' in model_name_lower:\n",
    "            class SwinFeatureExtractor(nn.Module):\n",
    "                def __init__(self, swin_model):\n",
    "                    super().__init__()\n",
    "                    self.patch_embed = swin_model.patch_embed\n",
    "                    self.layers = swin_model.layers\n",
    "                    self.norm = swin_model.norm\n",
    "                    self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "                \n",
    "                def forward(self, x):\n",
    "                    x = self.patch_embed(x)\n",
    "                    x = self.layers(x)\n",
    "                    x = self.norm(x)\n",
    "                    x = x.transpose(1, 2)\n",
    "                    x = self.avgpool(x)\n",
    "                    x = x.flatten(1)\n",
    "                    return x\n",
    "            \n",
    "            feature_extractor = SwinFeatureExtractor(model)\n",
    "            \n",
    "            if hasattr(model.head, 'fc'):\n",
    "                in_features = model.head.fc.in_features\n",
    "            elif hasattr(model.head, 'in_features'):\n",
    "                in_features = model.head.in_features\n",
    "            else:\n",
    "                in_features = model.num_features\n",
    "        \n",
    "        # Generic fallback\n",
    "        else:\n",
    "            print(f\"Warning: Unknown architecture '{model_name}', using generic extraction\")\n",
    "            modules = list(model.children())[:-1]\n",
    "            feature_extractor = nn.Sequential(*modules, nn.Flatten())\n",
    "            \n",
    "            dummy = torch.randn(1, 3, 224, 224)\n",
    "            with torch.no_grad():\n",
    "                out = feature_extractor(dummy)\n",
    "            in_features = out.shape[1]\n",
    "        \n",
    "        return feature_extractor, in_features\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UNIVERSAL EVIDENTIAL MODEL\n",
    "# ============================================================================\n",
    "\n",
    "class UniversalEvidentialModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_name: str, num_classes: int = 4, pretrained: bool = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load pretrained model\n",
    "        base_model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "        \n",
    "        # Extract feature extractor\n",
    "        self.feature_extractor, in_features = ArchitectureHandler.get_feature_extractor(\n",
    "            base_model, model_name\n",
    "        )\n",
    "        \n",
    "        # Evidential head\n",
    "        self.evidential_head = EvidentialLayer(in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.feature_extractor(x)\n",
    "        evidence = self.evidential_head(features)\n",
    "        return evidence\n",
    "    \n",
    "    def get_predictions_and_uncertainty(self, evidence: torch.Tensor) -> Tuple[\n",
    "        torch.Tensor, torch.Tensor, torch.Tensor\n",
    "    ]:\n",
    "        return self.evidential_head.get_predictions_and_uncertainty(evidence)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SAM OPTIMIZER (Solution 9)\n",
    "# ============================================================================\n",
    "\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    \n",
    "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
    "        defaults = dict(rho=rho, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "        \n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "            \n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = p.grad * scale.to(p)\n",
    "                p.add_(e_w)\n",
    "        \n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                p.data = self.state[p][\"old_p\"]\n",
    "        \n",
    "        self.base_optimizer.step()\n",
    "        \n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "    \n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device\n",
    "        norm = torch.norm(\n",
    "            torch.stack([\n",
    "                p.grad.norm(p=2).to(shared_device)\n",
    "                for group in self.param_groups for p in group[\"params\"]\n",
    "                if p.grad is not None\n",
    "            ]),\n",
    "            p=2\n",
    "        )\n",
    "        return norm\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CENTER LOSS (Solution 4)\n",
    "# ============================================================================\n",
    "\n",
    "class CenterLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes: int, embedding_dim: int, lambda_c: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lambda_c = lambda_c\n",
    "        \n",
    "        # Learnable class centers\n",
    "        self.centers = nn.Parameter(torch.randn(num_classes, embedding_dim))\n",
    "    \n",
    "    def forward(self, embeddings: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        centers_batch = self.centers[labels]\n",
    "        loss = F.mse_loss(embeddings, centers_batch)\n",
    "        return self.lambda_c * loss\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TRIPLET LOSS (Solution 3)\n",
    "# ============================================================================\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, margin: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, \n",
    "                negative: torch.Tensor) -> torch.Tensor:\n",
    "        distance_positive = F.pairwise_distance(anchor, positive, p=2)\n",
    "        distance_negative = F.pairwise_distance(anchor, negative, p=2)\n",
    "        \n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean()\n",
    "\n",
    "\n",
    "def create_triplet_batch(embeddings: torch.Tensor, labels: torch.Tensor) -> Tuple[\n",
    "    Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]\n",
    "]:\n",
    "    triplets = []\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        anchor = embeddings[i]\n",
    "        \n",
    "        # Positive: same class, different sample\n",
    "        positive_mask = (labels == label) & (torch.arange(len(labels), device=labels.device) != i)\n",
    "        if positive_mask.sum() > 0:\n",
    "            positive_idx = torch.where(positive_mask)[0][torch.randint(positive_mask.sum(), (1,))].item()\n",
    "            positive = embeddings[positive_idx]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Negative: different class, hardest (closest to anchor)\n",
    "        negative_mask = labels != label\n",
    "        if negative_mask.sum() > 0:\n",
    "            negative_candidates = embeddings[negative_mask]\n",
    "            distances = F.pairwise_distance(anchor.unsqueeze(0), negative_candidates)\n",
    "            hardest_idx = distances.argmin()\n",
    "            negative = negative_candidates[hardest_idx]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        triplets.append((anchor, positive, negative))\n",
    "    \n",
    "    if len(triplets) == 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    anchors = torch.stack([t[0] for t in triplets])\n",
    "    positives = torch.stack([t[1] for t in triplets])\n",
    "    negatives = torch.stack([t[2] for t in triplets])\n",
    "    \n",
    "    return anchors, positives, negatives\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MANIFOLD MIXUP (Solution 5)\n",
    "# ============================================================================\n",
    "\n",
    "class ManifoldMixup(nn.Module):\n",
    "    \n",
    "    def __init__(self, alpha: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, embeddings: torch.Tensor, labels: torch.Tensor) -> Tuple[\n",
    "        torch.Tensor, torch.Tensor, torch.Tensor, float\n",
    "    ]:\n",
    "        batch_size = embeddings.size(0)\n",
    "        \n",
    "        if self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "        else:\n",
    "            lam = 1\n",
    "        \n",
    "        index = torch.randperm(batch_size).to(embeddings.device)\n",
    "        \n",
    "        mixed_embeddings = lam * embeddings + (1 - lam) * embeddings[index]\n",
    "        labels_a = labels\n",
    "        labels_b = labels[index]\n",
    "        \n",
    "        return mixed_embeddings, labels_a, labels_b, lam\n",
    "\n",
    "\n",
    "def manifold_mixup_loss(criterion, outputs: torch.Tensor, labels_a: torch.Tensor,\n",
    "                        labels_b: torch.Tensor, lam: float) -> torch.Tensor:\n",
    "    loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# COSINE CLASSIFIER (Solution 6)\n",
    "# ============================================================================\n",
    "\n",
    "class CosineClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features: int, num_classes: int, scale: float = 30.0):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.num_classes = num_classes\n",
    "        self.scale = scale\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "    \n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        # Normalize features and weights\n",
    "        features_normalized = F.normalize(features, p=2, dim=1)\n",
    "        weight_normalized = F.normalize(self.weight, p=2, dim=1)\n",
    "        \n",
    "        # Cosine similarity\n",
    "        cosine = F.linear(features_normalized, weight_normalized)\n",
    "        \n",
    "        # Scale for stable training\n",
    "        logits = self.scale * cosine\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SE BLOCK (Solution 7)\n",
    "# ============================================================================\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch, channels, _, _ = x.size()\n",
    "        \n",
    "        # Squeeze: Global information embedding\n",
    "        y = self.squeeze(x).view(batch, channels)\n",
    "        \n",
    "        # Excitation: Channel attention\n",
    "        y = self.excitation(y).view(batch, channels, 1, 1)\n",
    "        \n",
    "        # Scale\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DISTANCE-AWARE LABEL SMOOTHING (Solution 8)\n",
    "# ============================================================================\n",
    "\n",
    "class DistanceAwareLabelSmoothing(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes: int, smoothing: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1.0 - smoothing\n",
    "    \n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        log_probs = F.log_softmax(logits, dim=1)\n",
    "        batch_size = logits.size(0)\n",
    "        \n",
    "        # Create smooth labels\n",
    "        smooth_labels = torch.zeros_like(log_probs)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            true_class = targets[i].item()\n",
    "            \n",
    "            # Confidence on true class\n",
    "            smooth_labels[i, true_class] = self.confidence\n",
    "            \n",
    "            # Distribute remaining mass based on distance\n",
    "            remaining = self.smoothing\n",
    "            total_weight = 0.0\n",
    "            \n",
    "            for k in range(self.num_classes):\n",
    "                if k != true_class:\n",
    "                    distance = abs(k - true_class)\n",
    "                    weight = 1.0 / (distance + 1)\n",
    "                    total_weight += weight\n",
    "            \n",
    "            # Normalize weights\n",
    "            for k in range(self.num_classes):\n",
    "                if k != true_class:\n",
    "                    distance = abs(k - true_class)\n",
    "                    weight = 1.0 / (distance + 1)\n",
    "                    smooth_labels[i, k] = remaining * (weight / total_weight)\n",
    "        \n",
    "        # KL divergence loss\n",
    "        loss = -(smooth_labels * log_probs).sum(dim=1).mean()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PROTOTYPICAL NETWORK (Solution 2)\n",
    "# ============================================================================\n",
    "\n",
    "class PrototypicalNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder: nn.Module, embedding_dim: int = 512):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.prototypes = None\n",
    "    \n",
    "    def compute_prototypes(self, support_embeddings: torch.Tensor, \n",
    "                          support_labels: torch.Tensor, num_classes: int) -> torch.Tensor:\n",
    "        prototypes = torch.zeros(num_classes, self.embedding_dim).to(support_embeddings.device)\n",
    "        \n",
    "        for k in range(num_classes):\n",
    "            class_mask = (support_labels == k)\n",
    "            class_embeddings = support_embeddings[class_mask]\n",
    "            \n",
    "            if class_embeddings.size(0) > 0:\n",
    "                prototypes[k] = class_embeddings.mean(dim=0)\n",
    "        \n",
    "        return prototypes\n",
    "    \n",
    "    def euclidean_distance(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        n = x.size(0)\n",
    "        m = y.size(0)\n",
    "        d = x.size(1)\n",
    "        \n",
    "        x = x.unsqueeze(1).expand(n, m, d)\n",
    "        y = y.unsqueeze(0).expand(n, m, d)\n",
    "        \n",
    "        return torch.pow(x - y, 2).sum(2)\n",
    "    \n",
    "    def forward(self, query_images: torch.Tensor, support_images: Optional[torch.Tensor] = None,\n",
    "                support_labels: Optional[torch.Tensor] = None, num_classes: int = 4) -> torch.Tensor:\n",
    "        query_embeddings = self.encoder(query_images)\n",
    "        \n",
    "        if support_images is not None:\n",
    "            support_embeddings = self.encoder(support_images)\n",
    "            prototypes = self.compute_prototypes(support_embeddings, support_labels, num_classes)\n",
    "        else:\n",
    "            prototypes = self.prototypes\n",
    "        \n",
    "        distances = self.euclidean_distance(query_embeddings, prototypes)\n",
    "        log_probs = F.log_softmax(-distances, dim=1)\n",
    "        \n",
    "        return log_probs\n",
    "    \n",
    "    def update_prototypes(self, train_loader, num_classes: int = 4):\n",
    "        self.encoder.eval()\n",
    "        all_embeddings = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in train_loader:\n",
    "                embeddings = self.encoder(images.to(next(self.encoder.parameters()).device))\n",
    "                all_embeddings.append(embeddings)\n",
    "                all_labels.append(labels)\n",
    "        \n",
    "        all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "        all_labels = torch.cat(all_labels, dim=0)\n",
    "        \n",
    "        self.prototypes = self.compute_prototypes(all_embeddings, all_labels, num_classes)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, alpha=1.0, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n",
    "        p_t = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "class ArchitectureLayerGroups:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_resnet_groups(model):\n",
    "        return [\n",
    "            list(model.conv1.parameters()) + list(model.bn1.parameters()) + list(model.layer1.parameters()),\n",
    "            list(model.layer2.parameters()),\n",
    "            list(model.layer3.parameters()),\n",
    "            list(model.layer4.parameters()),\n",
    "            list(model.fc.parameters())\n",
    "        ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_vit_groups(model):\n",
    "        if hasattr(model, 'blocks'):\n",
    "            num_blocks = len(model.blocks)\n",
    "        else:\n",
    "            num_blocks = 12\n",
    "        \n",
    "        split1 = num_blocks // 4\n",
    "        split2 = num_blocks // 2\n",
    "        split3 = 3 * num_blocks // 4\n",
    "        \n",
    "        groups = []\n",
    "        \n",
    "        # Group 0: Patch embedding + early blocks\n",
    "        group0 = []\n",
    "        if hasattr(model, 'patch_embed'):\n",
    "            group0.extend(list(model.patch_embed.parameters()))\n",
    "        if hasattr(model, 'pos_embed'):\n",
    "            group0.append(model.pos_embed)\n",
    "        if hasattr(model, 'cls_token'):\n",
    "            group0.append(model.cls_token)\n",
    "        \n",
    "        if hasattr(model, 'blocks'):\n",
    "            for i in range(0, split1):\n",
    "                group0.extend(list(model.blocks[i].parameters()))\n",
    "        groups.append(group0)\n",
    "        \n",
    "        # Group 1-3: Block ranges\n",
    "        if hasattr(model, 'blocks'):\n",
    "            groups.append([p for i in range(split1, split2) for p in model.blocks[i].parameters()])\n",
    "            groups.append([p for i in range(split2, split3) for p in model.blocks[i].parameters()])\n",
    "            \n",
    "            group3 = [p for i in range(split3, num_blocks) for p in model.blocks[i].parameters()]\n",
    "            if hasattr(model, 'norm'):\n",
    "                group3.extend(list(model.norm.parameters()))\n",
    "            groups.append(group3)\n",
    "        else:\n",
    "            groups.extend([[], [], []])\n",
    "        \n",
    "        # Group 4: Head\n",
    "        group4 = []\n",
    "        if hasattr(model, 'head'):\n",
    "            group4.extend(list(model.head.parameters()))\n",
    "        elif hasattr(model, 'fc'):\n",
    "            group4.extend(list(model.fc.parameters()))\n",
    "        groups.append(group4)\n",
    "        \n",
    "        return groups\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_swin_groups(model):\n",
    "        groups = []\n",
    "        \n",
    "        # Group 0: Patch embed + Stage 1\n",
    "        group0 = []\n",
    "        if hasattr(model, 'patch_embed'):\n",
    "            group0.extend(list(model.patch_embed.parameters()))\n",
    "        if hasattr(model, 'layers') and len(model.layers) > 0:\n",
    "            group0.extend(list(model.layers[0].parameters()))\n",
    "        groups.append(group0)\n",
    "        \n",
    "        # Groups 1-3: Stages 2-4\n",
    "        if hasattr(model, 'layers'):\n",
    "            for i in range(1, min(4, len(model.layers))):\n",
    "                groups.append(list(model.layers[i].parameters()))\n",
    "            \n",
    "            # Pad if needed\n",
    "            while len(groups) < 4:\n",
    "                groups.append([])\n",
    "            \n",
    "            # Add norm to last group\n",
    "            if hasattr(model, 'norm'):\n",
    "                groups[3].extend(list(model.norm.parameters()))\n",
    "        else:\n",
    "            groups.extend([[], [], []])\n",
    "        \n",
    "        # Group 4: Head\n",
    "        group4 = []\n",
    "        if hasattr(model, 'head'):\n",
    "            if hasattr(model.head, 'fc'):\n",
    "                group4.extend(list(model.head.fc.parameters()))\n",
    "            else:\n",
    "                group4.extend(list(model.head.parameters()))\n",
    "        elif hasattr(model, 'fc'):\n",
    "            group4.extend(list(model.fc.parameters()))\n",
    "        groups.append(group4)\n",
    "        \n",
    "        return groups\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_efficientnet_groups(model):\n",
    "        children = list(model.children())\n",
    "        n_children = len(children)\n",
    "        n_per_group = max(1, n_children // 5)\n",
    "        \n",
    "        groups = []\n",
    "        for i in range(4):\n",
    "            start = i * n_per_group\n",
    "            end = (i + 1) * n_per_group if i < 3 else n_children - 1\n",
    "            group_params = []\n",
    "            for child in children[start:end]:\n",
    "                if hasattr(child, 'parameters'):\n",
    "                    group_params.extend(list(child.parameters()))\n",
    "            groups.append(group_params)\n",
    "        \n",
    "        # Last group (classifier)\n",
    "        group4 = []\n",
    "        for child in children[4*n_per_group:]:\n",
    "            if hasattr(child, 'parameters'):\n",
    "                group4.extend(list(child.parameters()))\n",
    "        groups.append(group4)\n",
    "        \n",
    "        return groups\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mobilenet_groups(model):\n",
    "        if hasattr(model, 'features'):\n",
    "            features = model.features\n",
    "            n_features = len(features)\n",
    "            \n",
    "            return [\n",
    "                list(features[:n_features//4].parameters()),\n",
    "                list(features[n_features//4:n_features//2].parameters()),\n",
    "                list(features[n_features//2:3*n_features//4].parameters()),\n",
    "                list(features[3*n_features//4:].parameters()),\n",
    "                list(model.classifier.parameters()) if hasattr(model, 'classifier') else []\n",
    "            ]\n",
    "        else:\n",
    "            # Fallback\n",
    "            all_params = list(model.parameters())\n",
    "            n = len(all_params)\n",
    "            return [\n",
    "                all_params[:n//5],\n",
    "                all_params[n//5:2*n//5],\n",
    "                all_params[2*n//5:3*n//5],\n",
    "                all_params[3*n//5:4*n//5],\n",
    "                all_params[4*n//5:]\n",
    "            ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_layer_groups(model, model_name):\n",
    "        model_name_lower = model_name.lower()\n",
    "        \n",
    "        if 'resnet' in model_name_lower or 'resnext' in model_name_lower:\n",
    "            return ArchitectureLayerGroups.get_resnet_groups(model)\n",
    "        elif 'vit' in model_name_lower:\n",
    "            return ArchitectureLayerGroups.get_vit_groups(model)\n",
    "        elif 'swin' in model_name_lower:\n",
    "            return ArchitectureLayerGroups.get_swin_groups(model)\n",
    "        elif 'efficientnet' in model_name_lower:\n",
    "            return ArchitectureLayerGroups.get_efficientnet_groups(model)\n",
    "        elif 'mobilenet' in model_name_lower:\n",
    "            return ArchitectureLayerGroups.get_mobilenet_groups(model)\n",
    "        else:\n",
    "            # Generic fallback\n",
    "            all_params = list(model.parameters())\n",
    "            n = len(all_params)\n",
    "            return [\n",
    "                all_params[:n//5],\n",
    "                all_params[n//5:2*n//5],\n",
    "                all_params[2*n//5:3*n//5],\n",
    "                all_params[3*n//5:4*n//5],\n",
    "                all_params[4*n//5:]\n",
    "            ]\n",
    "\n",
    "\n",
    "class ProgressiveClassifier(BaseClassifier):\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.model = timm.create_model(\n",
    "            self.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=self.num_classes\n",
    "        )\n",
    "        \n",
    "        # Get layer groups for discriminative LRs\n",
    "        self.layer_groups = ArchitectureLayerGroups.get_layer_groups(\n",
    "            self.model, self.model_name\n",
    "        )\n",
    "        \n",
    "        # Detect architecture type for scheduler selection\n",
    "        self.architecture_type = 'transformer' if any(\n",
    "            x in self.model_name.lower() for x in ['vit', 'swin', 'transformer']\n",
    "        ) else 'cnn'\n",
    "    \n",
    "    def forward(self, images):\n",
    "        return self.model(images)\n",
    "    \n",
    "    def compute_loss(self, outputs, labels):\n",
    "        if not hasattr(self, 'focal_loss'):\n",
    "            self.focal_loss = FocalLoss(alpha=1.0, gamma=2.0).to(self.device)\n",
    "        return self.focal_loss(outputs, labels)\n",
    "    \n",
    "    def _get_discriminative_params(self, base_lr):\n",
    "        lr_multipliers = [1/100, 1/10, 1/3, 1.0, 10.0]\n",
    "        \n",
    "        param_groups = []\n",
    "        for params, mult in zip(self.layer_groups, lr_multipliers):\n",
    "            if params:\n",
    "                param_groups.append({\n",
    "                    'params': params,\n",
    "                    'lr': base_lr * mult\n",
    "                })\n",
    "        \n",
    "        return param_groups\n",
    "    \n",
    "    def fit(self, train_loader, val_loader, epochs=30, lr=1e-4,\n",
    "            use_sam=False, primary_metric='recall',\n",
    "            patience=10, min_delta=0.001):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"PROGRESSIVE FINE-TUNING: {self.model_name}\")\n",
    "        print(f\"Optimizing for: {primary_metric.upper()}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Phase 1: Classifier only (5 epochs)\n",
    "        print(\"=\"*80)\n",
    "        print(\"PHASE 1: Training Classifier Only (Backbone Frozen)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        self._train_phase(\n",
    "            phase=1,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            epochs=min(5, epochs),\n",
    "            lr=lr * 10,  # Higher LR for random classifier\n",
    "            freeze_mode='classifier_only',\n",
    "            use_sam=False,\n",
    "            primary_metric=primary_metric,\n",
    "            patience=5,\n",
    "            min_delta=min_delta\n",
    "        )\n",
    "        \n",
    "        # Phase 2: Top 50% layers (10 epochs)\n",
    "        remaining_epochs = max(0, epochs - 5)\n",
    "        if remaining_epochs > 0:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"PHASE 2: Fine-tuning Top Layers (Bottom 50% Frozen)\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            self._train_phase(\n",
    "                phase=2,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                epochs=min(10, remaining_epochs),\n",
    "                lr=lr,\n",
    "                freeze_mode='top_50',\n",
    "                use_sam=False,\n",
    "                primary_metric=primary_metric,\n",
    "                patience=7,\n",
    "                min_delta=min_delta\n",
    "            )\n",
    "        \n",
    "        # Phase 3: All layers with discriminative LRs (remaining epochs)\n",
    "        remaining_epochs = max(0, epochs - 15)\n",
    "        if remaining_epochs > 0:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"PHASE 3: Discriminative Fine-Tuning (All Layers)\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            self._train_phase(\n",
    "                phase=3,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                epochs=remaining_epochs,\n",
    "                lr=lr,\n",
    "                freeze_mode='all_discriminative',\n",
    "                use_sam=use_sam,  # SAM only in phase 3\n",
    "                primary_metric=primary_metric,\n",
    "                patience=patience,\n",
    "                min_delta=min_delta\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"PROGRESSIVE FINE-TUNING COMPLETE\")\n",
    "        print(f\"Final Best {primary_metric.capitalize()}: {self.best_metric_value:.4f} ‚òÖ\")\n",
    "        print(f\"Final Best Recall: {self.best_recall:.4f}\")\n",
    "        print(f\"Final Best Accuracy: {self.best_acc:.2f}%\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def _train_phase(self, phase, train_loader, val_loader, epochs, lr,\n",
    "                    freeze_mode, use_sam, primary_metric, patience, min_delta):\n",
    "        \n",
    "        # Freeze/unfreeze according to mode\n",
    "        if freeze_mode == 'classifier_only':\n",
    "            # Freeze all except classifier\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            if self.layer_groups[-1]:\n",
    "                for param in self.layer_groups[-1]:\n",
    "                    param.requires_grad = True\n",
    "                    \n",
    "        elif freeze_mode == 'top_50':\n",
    "            # Unfreeze top 50%\n",
    "            all_params = list(self.model.parameters())\n",
    "            n_params = len(all_params)\n",
    "            for param in all_params[:n_params//2]:\n",
    "                param.requires_grad = False\n",
    "            for param in all_params[n_params//2:]:\n",
    "                param.requires_grad = True\n",
    "                \n",
    "        elif freeze_mode == 'all_discriminative':\n",
    "            # Unfreeze everything\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        # Create optimizer\n",
    "        if freeze_mode == 'all_discriminative':\n",
    "            # Discriminative LRs\n",
    "            param_groups = self._get_discriminative_params(lr)\n",
    "            print(f\"Discriminative LR groups:\")\n",
    "            for i, group in enumerate(param_groups):\n",
    "                print(f\"  Group {i}: {len(list(group['params']))} params, LR={group['lr']:.2e}\")\n",
    "        else:\n",
    "            # Single LR\n",
    "            param_groups = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        \n",
    "        if use_sam:\n",
    "            optimizer = SAM(param_groups, optim.AdamW, lr=lr, weight_decay=0.01, rho=0.05)\n",
    "        else:\n",
    "            optimizer = optim.AdamW(param_groups, lr=lr, weight_decay=0.01)\n",
    "        \n",
    "        # Create scheduler\n",
    "        if self.architecture_type == 'cnn':\n",
    "            scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer.base_optimizer if use_sam else optimizer,\n",
    "                max_lr=lr if freeze_mode != 'all_discriminative' else lr * 10,  # Max LR for classifier\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=len(train_loader),\n",
    "                pct_start=0.3,\n",
    "                div_factor=25.0,\n",
    "                final_div_factor=1000.0\n",
    "            )\n",
    "        else:  # transformer\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer.base_optimizer if use_sam else optimizer,\n",
    "                T_max=epochs,\n",
    "                eta_min=1e-7\n",
    "            )\n",
    "        \n",
    "        # Scaler\n",
    "        scaler = torch.amp.GradScaler(enabled=(self.device == 'cuda' and not use_sam))\n",
    "        \n",
    "        # Training loop\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Train\n",
    "            train_loss, train_acc, train_recall = self.train_epoch(\n",
    "                train_loader, optimizer, scaler if not use_sam else None, scheduler\n",
    "            )\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc, val_recall, val_prec, val_f1, primary_value = self.validate_epoch(val_loader)\n",
    "            \n",
    "            # Record history\n",
    "            self.history.append({\n",
    "                'phase': phase,\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'train_acc': train_acc,\n",
    "                'train_recall': train_recall,\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc,\n",
    "                'val_recall': val_recall,\n",
    "                'val_precision': val_prec,\n",
    "                'val_f1': val_f1,\n",
    "                f'val_{primary_metric}': primary_value\n",
    "            })\n",
    "            \n",
    "            # Check improvement\n",
    "            improved = False\n",
    "            if primary_value > self.best_metric_value + min_delta:\n",
    "                self.best_metric_value = primary_value\n",
    "                improved = True\n",
    "            if val_recall > self.best_recall:\n",
    "                self.best_recall = val_recall\n",
    "            if val_acc > self.best_acc:\n",
    "                self.best_acc = val_acc\n",
    "            if val_f1 > self.best_f1:\n",
    "                self.best_f1 = val_f1\n",
    "            \n",
    "            # Print\n",
    "            if improved:\n",
    "                print(f\"  [Epoch {epoch+1}/{epochs}] {primary_metric}: {primary_value:.4f} ‚òÖ, \"\n",
    "                      f\"Acc: {val_acc:.2f}%, Recall: {val_recall:.4f}\")\n",
    "                self.best_epoch = epoch + 1\n",
    "                torch.save(self.model.state_dict(),\n",
    "                          f'ProgressiveClassifier_{self.model_name}_best.pth')\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                print(f\"  [Epoch {epoch+1}/{epochs}] {primary_metric}: {primary_value:.4f}, \"\n",
    "                      f\"Acc: {val_acc:.2f}%\")\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"  Early stopping (patience={patience})\")\n",
    "                break\n",
    "            \n",
    "            # Step scheduler (if not OneCycleLR)\n",
    "            if not isinstance(scheduler, optim.lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "        \n",
    "        print(f\"√¢≈ì‚Ä¶ Phase {phase} Complete - Best {primary_metric}: {self.best_metric_value:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1. BASELINE CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "class BaselineClassifier(BaseClassifier):\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.model = timm.create_model(\n",
    "            self.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=self.num_classes\n",
    "        )\n",
    "    \n",
    "    def forward(self, images):\n",
    "        return self.model(images)\n",
    "    \n",
    "    def compute_loss(self, outputs, labels):\n",
    "        return F.cross_entropy(outputs, labels)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2. EVIDENTIAL CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "class EvidentialClassifier(BaseClassifier):\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.evidential_model = UniversalEvidentialModel(\n",
    "            self.model_name,\n",
    "            num_classes=self.num_classes,\n",
    "            pretrained=True\n",
    "        )\n",
    "        self.model = self.evidential_model\n",
    "        self.criterion = EvidentialLoss(self.num_classes, lam=0.5)\n",
    "    \n",
    "    def forward(self, images):\n",
    "        return self.evidential_model(images)\n",
    "    \n",
    "    def compute_loss(self, evidence, labels):\n",
    "        return self.criterion(evidence, labels)\n",
    "    \n",
    "    def get_predictions(self, evidence):\n",
    "        probs, _, _ = self.evidential_model.get_predictions_and_uncertainty(evidence)\n",
    "        return torch.argmax(probs, dim=1)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 3. METRIC LEARNING CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "class MetricLearningClassifier(BaseClassifier):\n",
    "    \n",
    "    def build_model(self):\n",
    "        # Base model\n",
    "        base = timm.create_model(self.model_name, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Get feature dimension\n",
    "        if hasattr(base, 'fc'):\n",
    "            in_features = base.fc.in_features\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        elif hasattr(base, 'head'):\n",
    "            in_features = base.head.in_features\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        else:\n",
    "            in_features = 512\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding_dim = 256\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(in_features, self.embedding_dim),\n",
    "            nn.BatchNorm1d(self.embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(self.embedding_dim, self.num_classes)\n",
    "        \n",
    "        # Losses\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.center_loss = CenterLoss(self.num_classes, self.embedding_dim, lambda_c=0.1)\n",
    "        self.triplet_loss = TripletLoss(margin=1.0)\n",
    "        \n",
    "        # Combined model\n",
    "        self.model = nn.ModuleDict({\n",
    "            'feature_extractor': self.feature_extractor,\n",
    "            'embedding': self.embedding,\n",
    "            'classifier': self.classifier,\n",
    "            'center_loss': self.center_loss\n",
    "        })\n",
    "    \n",
    "    def forward(self, images):\n",
    "        features = self.feature_extractor(images)\n",
    "        embeddings = self.embedding(features)\n",
    "        logits = self.classifier(embeddings)\n",
    "        return logits, embeddings\n",
    "    \n",
    "    def compute_loss(self, outputs, labels):\n",
    "        logits, embeddings = outputs\n",
    "        \n",
    "        # CrossEntropy\n",
    "        ce = self.ce_loss(logits, labels)\n",
    "        \n",
    "        # Center Loss\n",
    "        center = self.center_loss(embeddings, labels)\n",
    "        \n",
    "        # Triplet Loss\n",
    "        anchors, positives, negatives = create_triplet_batch(embeddings, labels)\n",
    "        if anchors is not None:\n",
    "            triplet = self.triplet_loss(anchors, positives, negatives)\n",
    "        else:\n",
    "            triplet = torch.tensor(0.0).to(embeddings.device)\n",
    "        \n",
    "        return ce + center + 0.1 * triplet\n",
    "    \n",
    "    def get_predictions(self, outputs):\n",
    "        logits, _ = outputs\n",
    "        return torch.argmax(logits, dim=1)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 4. REGULARIZED CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "class RegularizedClassifier(BaseClassifier):\n",
    "    \n",
    "    def build_model(self):\n",
    "        base = timm.create_model(self.model_name, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Extract feature extractor\n",
    "        if hasattr(base, 'fc'):\n",
    "            in_features = base.fc.in_features\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        elif hasattr(base, 'head'):\n",
    "            in_features = base.head.in_features\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        else:\n",
    "            in_features = 512\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features, self.num_classes)\n",
    "        \n",
    "        # Regularizers\n",
    "        self.manifold_mixup = ManifoldMixup(alpha=0.2)\n",
    "        self.criterion = DistanceAwareLabelSmoothing(self.num_classes, smoothing=0.1)\n",
    "        \n",
    "        self.model = nn.ModuleDict({\n",
    "            'feature_extractor': self.feature_extractor,\n",
    "            'classifier': self.classifier\n",
    "        })\n",
    "        \n",
    "        self.mixup_enabled = True\n",
    "    \n",
    "    def forward(self, images, labels=None):\n",
    "        features = self.feature_extractor(images)\n",
    "        \n",
    "        # Apply manifold mixup during training\n",
    "        if self.training and self.mixup_enabled and labels is not None:\n",
    "            features, labels_a, labels_b, lam = self.manifold_mixup(features, labels)\n",
    "            logits = self.classifier(features)\n",
    "            return logits, labels_a, labels_b, lam\n",
    "        else:\n",
    "            logits = self.classifier(features)\n",
    "            return logits\n",
    "    \n",
    "    def compute_loss(self, outputs, labels):\n",
    "        if isinstance(outputs, tuple) and len(outputs) == 4:\n",
    "            logits, labels_a, labels_b, lam = outputs\n",
    "            loss = manifold_mixup_loss(self.criterion, logits, labels_a, labels_b, lam)\n",
    "        else:\n",
    "            logits = outputs\n",
    "            loss = self.criterion(logits, labels)\n",
    "        return loss\n",
    "    \n",
    "    def get_predictions(self, outputs):\n",
    "        if isinstance(outputs, tuple):\n",
    "            logits = outputs[0]\n",
    "        else:\n",
    "            logits = outputs\n",
    "        return torch.argmax(logits, dim=1)\n",
    "    \n",
    "    def train_epoch(self, train_loader, optimizer, scaler=None, scheduler=None):\n",
    "        self.model.train()\n",
    "        self.mixup_enabled = True\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        from .techniques import SAM\n",
    "        is_sam = isinstance(optimizer, SAM)\n",
    "        use_amp = not is_sam and self.device == 'cuda'\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if is_sam:\n",
    "                outputs = self.forward(images, labels)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.first_step(zero_grad=True)\n",
    "                \n",
    "                outputs = self.forward(images, labels)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.second_step(zero_grad=True)\n",
    "            else:\n",
    "                if use_amp and scaler:\n",
    "                    with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                        outputs = self.forward(images, labels)\n",
    "                        loss = self.compute_loss(outputs, labels)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = self.forward(images, labels)\n",
    "                    loss = self.compute_loss(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            if scheduler and isinstance(scheduler, (\n",
    "                torch.optim.lr_scheduler.OneCycleLR,\n",
    "                torch.optim.lr_scheduler.SequentialLR\n",
    "            )):\n",
    "                scheduler.step()\n",
    "            \n",
    "            running_loss += loss.detach().item() * images.size(0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                preds = self.get_predictions(outputs)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        from sklearn.metrics import accuracy_score, recall_score\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "        acc = accuracy_score(all_labels, all_preds) * 100\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        return avg_loss, acc, recall\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 5. ATTENTION-ENHANCED CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "class AttentionEnhancedClassifier(BaseClassifier):\n",
    "    \n",
    "    def build_model(self):\n",
    "        base = timm.create_model(self.model_name, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Add SE blocks (simplified - add to last layer)\n",
    "        if hasattr(base, 'layer4'):\n",
    "            for block in base.layer4:\n",
    "                if hasattr(block, 'conv2'):\n",
    "                    channels = block.conv2.out_channels\n",
    "                    block.se = SEBlock(channels, reduction=16)\n",
    "        \n",
    "        # Get feature dimension\n",
    "        if hasattr(base, 'fc'):\n",
    "            in_features = base.fc.in_features\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        elif hasattr(base, 'head'):\n",
    "            in_features = base.head.in_features\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        else:\n",
    "            in_features = 512\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        \n",
    "        # Cosine classifier\n",
    "        self.cosine_classifier = CosineClassifier(in_features, self.num_classes, scale=30.0)\n",
    "        \n",
    "        self.model = nn.ModuleDict({\n",
    "            'feature_extractor': self.feature_extractor,\n",
    "            'cosine_classifier': self.cosine_classifier\n",
    "        })\n",
    "    \n",
    "    def forward(self, images):\n",
    "        features = self.feature_extractor(images)\n",
    "        logits = self.cosine_classifier(features)\n",
    "        return logits\n",
    "    \n",
    "    def compute_loss(self, outputs, labels):\n",
    "        return F.cross_entropy(outputs, labels)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 6. PROGRESSIVE EVIDENTIAL CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "class ProgressiveEvidentialClassifier(BaseClassifier):\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.evidential_model = UniversalEvidentialModel(\n",
    "            self.model_name,\n",
    "            num_classes=self.num_classes,\n",
    "            pretrained=True\n",
    "        )\n",
    "        self.model = self.evidential_model\n",
    "        self.criterion = EvidentialLoss(self.num_classes, lam=0.5)\n",
    "    \n",
    "    def forward(self, images):\n",
    "        return self.evidential_model(images)\n",
    "    \n",
    "    def compute_loss(self, evidence, labels):\n",
    "        return self.criterion(evidence, labels)\n",
    "    \n",
    "    def get_predictions(self, evidence):\n",
    "        probs, _, _ = self.evidential_model.get_predictions_and_uncertainty(evidence)\n",
    "        return torch.argmax(probs, dim=1)\n",
    "    \n",
    "    def fit(self, train_loader, val_loader, epochs: int = 30, lr: float = 1e-4,\n",
    "            use_sam: bool = False, primary_metric: str = 'recall',\n",
    "            patience: int = 10, min_delta: float = 0.001):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"PROGRESSIVE EVIDENTIAL TRAINING\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Phase 1: Classifier only\n",
    "        print(\"Phase 1: Training Evidential Head Only (5 epochs)\")\n",
    "        for param in self.model.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model.evidential_head.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        super().fit(train_loader, val_loader, epochs=5, lr=lr*10, use_sam=False,\n",
    "                   primary_metric=primary_metric, patience=5, min_delta=min_delta)\n",
    "        \n",
    "        # Phase 2: All layers\n",
    "        print(\"\\nPhase 2: Fine-tuning All Layers (remaining epochs)\")\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        remaining_epochs = epochs - 5\n",
    "        super().fit(train_loader, val_loader, epochs=remaining_epochs, lr=lr, use_sam=use_sam,\n",
    "                   primary_metric=primary_metric, patience=patience, min_delta=min_delta)\n",
    "        \n",
    "        return self.history\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 7. CLINICAL-GRADE CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "class ClinicalGradeClassifier(BaseClassifier):\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.evidential_model = UniversalEvidentialModel(\n",
    "            self.model_name,\n",
    "            num_classes=self.num_classes,\n",
    "            pretrained=True\n",
    "        )\n",
    "        \n",
    "        # Center loss\n",
    "        embedding_dim = 512\n",
    "        self.center_loss = CenterLoss(self.num_classes, embedding_dim, lambda_c=0.1)\n",
    "        \n",
    "        # Manifold mixup\n",
    "        self.manifold_mixup = ManifoldMixup(alpha=0.2)\n",
    "        \n",
    "        # Losses\n",
    "        self.evidential_loss = EvidentialLoss(self.num_classes, lam=0.5)\n",
    "        \n",
    "        self.model = self.evidential_model\n",
    "        self.mixup_enabled = True\n",
    "    \n",
    "    def forward(self, images, labels=None):\n",
    "        features = self.evidential_model.feature_extractor(images)\n",
    "        \n",
    "        # Apply manifold mixup during training\n",
    "        if self.training and self.mixup_enabled and labels is not None:\n",
    "            features, labels_a, labels_b, lam = self.manifold_mixup(features, labels)\n",
    "            evidence = self.evidential_model.evidential_head(features)\n",
    "            return evidence, features, labels_a, labels_b, lam\n",
    "        else:\n",
    "            evidence = self.evidential_model.evidential_head(features)\n",
    "            return evidence, features\n",
    "    \n",
    "    def compute_loss(self, outputs, labels):\n",
    "        if len(outputs) == 5:\n",
    "            evidence, features, labels_a, labels_b, lam = outputs\n",
    "            loss_ev = manifold_mixup_loss(self.evidential_loss, evidence, labels_a, labels_b, lam)\n",
    "            loss_center = self.center_loss(features, labels)\n",
    "        else:\n",
    "            evidence, features = outputs\n",
    "            loss_ev = self.evidential_loss(evidence, labels)\n",
    "            loss_center = self.center_loss(features, labels)\n",
    "        \n",
    "        return loss_ev + loss_center\n",
    "    \n",
    "    def get_predictions(self, outputs):\n",
    "        if isinstance(outputs, tuple):\n",
    "            evidence = outputs[0]\n",
    "        else:\n",
    "            evidence = outputs\n",
    "        \n",
    "        probs, _, _ = self.evidential_model.get_predictions_and_uncertainty(evidence)\n",
    "        return torch.argmax(probs, dim=1)\n",
    "    \n",
    "    def fit(self, train_loader, val_loader, epochs: int = 30, lr: float = 1e-4,\n",
    "            use_sam: bool = True, primary_metric: str = 'recall',\n",
    "            patience: int = 10, min_delta: float = 0.001):\n",
    "        return super().fit(train_loader, val_loader, epochs, lr, use_sam=True,\n",
    "                          primary_metric=primary_metric, patience=patience, min_delta=min_delta)\n",
    "    \n",
    "    def train_epoch(self, train_loader, optimizer, scaler=None, scheduler=None):\n",
    "        self.model.train()\n",
    "        self.mixup_enabled = True\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        from .techniques import SAM\n",
    "        is_sam = isinstance(optimizer, SAM)\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if is_sam:\n",
    "                outputs = self.forward(images, labels)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.first_step(zero_grad=True)\n",
    "                \n",
    "                outputs = self.forward(images, labels)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.second_step(zero_grad=True)\n",
    "            else:\n",
    "                outputs = self.forward(images, labels)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            if scheduler and isinstance(scheduler, (\n",
    "                torch.optim.lr_scheduler.OneCycleLR,\n",
    "                torch.optim.lr_scheduler.SequentialLR\n",
    "            )):\n",
    "                scheduler.step()\n",
    "            \n",
    "            running_loss += loss.detach().item() * images.size(0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                preds = self.get_predictions(outputs)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        from sklearn.metrics import accuracy_score, recall_score\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "        acc = accuracy_score(all_labels, all_preds) * 100\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        return avg_loss, acc, recall\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 8. HYBRID TRANSFORMER CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "class HybridTransformerClassifier(BaseClassifier):\n",
    "    \n",
    "    def build_model(self):\n",
    "        # Only works with CNN-based models\n",
    "        if 'vit' in self.model_name.lower() or 'swin' in self.model_name.lower():\n",
    "            print(f\"Warning: HybridTransformer works best with CNN models. Using {self.model_name} as-is.\")\n",
    "            self.model = timm.create_model(self.model_name, pretrained=True, num_classes=self.num_classes)\n",
    "            return\n",
    "        \n",
    "        # CNN backbone\n",
    "        cnn_base = timm.create_model(self.model_name, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Extract CNN features (before classifier)\n",
    "        if hasattr(cnn_base, 'fc'):\n",
    "            self.cnn_features = nn.Sequential(*list(cnn_base.children())[:-2])\n",
    "            in_features = cnn_base.fc.in_features\n",
    "        elif hasattr(cnn_base, 'head'):\n",
    "            self.cnn_features = nn.Sequential(*list(cnn_base.children())[:-2])\n",
    "            in_features = cnn_base.head.in_features\n",
    "        else:\n",
    "            self.cnn_features = nn.Sequential(*list(cnn_base.children())[:-1])\n",
    "            in_features = 512\n",
    "        \n",
    "        # Simple transformer layer\n",
    "        self.transformer = nn.TransformerEncoderLayer(\n",
    "            d_model=in_features,\n",
    "            nhead=8,\n",
    "            dim_feedforward=in_features * 4,\n",
    "            dropout=0.1,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(in_features, self.num_classes)\n",
    "        \n",
    "        self.model = nn.ModuleDict({\n",
    "            'cnn_features': self.cnn_features,\n",
    "            'transformer': self.transformer,\n",
    "            'classifier': self.classifier\n",
    "        })\n",
    "    \n",
    "    def forward(self, images):\n",
    "        # CNN features\n",
    "        features = self.cnn_features(images)\n",
    "        \n",
    "        # Global average pooling\n",
    "        if len(features.shape) == 4:\n",
    "            features = F.adaptive_avg_pool2d(features, 1).flatten(1)\n",
    "        \n",
    "        # Add batch dimension for transformer\n",
    "        features = features.unsqueeze(1)  # [B, 1, C]\n",
    "        \n",
    "        # Transformer\n",
    "        features = self.transformer(features)\n",
    "        features = features.squeeze(1)  # [B, C]\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "    def compute_loss(self, outputs, labels):\n",
    "        return F.cross_entropy(outputs, labels)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 9. ULTIMATE RECALL-OPTIMIZED CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "class UltimateRecallOptimizedClassifier(BaseClassifier):\n",
    "    \n",
    "    def build_model(self):\n",
    "        # Base model with SE blocks\n",
    "        base = timm.create_model(self.model_name, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Add SE blocks\n",
    "        if hasattr(base, 'layer4'):\n",
    "            for block in base.layer4:\n",
    "                if hasattr(block, 'conv2'):\n",
    "                    channels = block.conv2.out_channels\n",
    "                    block.se = SEBlock(channels, reduction=16)\n",
    "        \n",
    "        # Extract feature extractor\n",
    "        if hasattr(base, 'fc'):\n",
    "            in_features = base.fc.in_features\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        elif hasattr(base, 'head'):\n",
    "            in_features = base.head.in_features\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        else:\n",
    "            in_features = 512\n",
    "            self.feature_extractor = nn.Sequential(*list(base.children())[:-1], nn.Flatten())\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding_dim = 256\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(in_features, self.embedding_dim),\n",
    "            nn.BatchNorm1d(self.embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Evidential head\n",
    "        self.evidential_head = EvidentialLayer(self.embedding_dim, self.num_classes)\n",
    "        \n",
    "        # Cosine classifier (alternative)\n",
    "        self.cosine_classifier = CosineClassifier(self.embedding_dim, self.num_classes, scale=30.0)\n",
    "        \n",
    "        # Losses\n",
    "        self.evidential_loss = EvidentialLoss(self.num_classes, lam=0.5)\n",
    "        self.center_loss = CenterLoss(self.num_classes, self.embedding_dim, lambda_c=0.1)\n",
    "        \n",
    "        # Regularizers\n",
    "        self.manifold_mixup = ManifoldMixup(alpha=0.2)\n",
    "        \n",
    "        self.model = nn.ModuleDict({\n",
    "            'feature_extractor': self.feature_extractor,\n",
    "            'embedding': self.embedding,\n",
    "            'evidential_head': self.evidential_head,\n",
    "            'cosine_classifier': self.cosine_classifier,\n",
    "            'center_loss': self.center_loss\n",
    "        })\n",
    "        \n",
    "        self.mixup_enabled = True\n",
    "        self.use_evidential = True\n",
    "    \n",
    "    def forward(self, images, labels=None):\n",
    "        # Features\n",
    "        features = self.feature_extractor(images)\n",
    "        embeddings = self.embedding(features)\n",
    "        \n",
    "        # Apply manifold mixup during training\n",
    "        if self.training and self.mixup_enabled and labels is not None:\n",
    "            embeddings, labels_a, labels_b, lam = self.manifold_mixup(embeddings, labels)\n",
    "            \n",
    "            if self.use_evidential:\n",
    "                evidence = self.evidential_head(embeddings)\n",
    "                return evidence, embeddings, labels_a, labels_b, lam\n",
    "            else:\n",
    "                logits = self.cosine_classifier(embeddings)\n",
    "                return logits, embeddings, labels_a, labels_b, lam\n",
    "        else:\n",
    "            if self.use_evidential:\n",
    "                evidence = self.evidential_head(embeddings)\n",
    "                return evidence, embeddings\n",
    "            else:\n",
    "                logits = self.cosine_classifier(embeddings)\n",
    "                return logits, embeddings\n",
    "    \n",
    "    def compute_loss(self, outputs, labels):\n",
    "        if len(outputs) == 5:\n",
    "            pred, embeddings, labels_a, labels_b, lam = outputs\n",
    "            \n",
    "            if self.use_evidential:\n",
    "                loss_pred = lam * self.evidential_loss(pred, labels_a) + \\\n",
    "                           (1 - lam) * self.evidential_loss(pred, labels_b)\n",
    "            else:\n",
    "                loss_pred = lam * F.cross_entropy(pred, labels_a) + \\\n",
    "                           (1 - lam) * F.cross_entropy(pred, labels_b)\n",
    "            \n",
    "            loss_center = self.center_loss(embeddings, labels)\n",
    "        else:\n",
    "            pred, embeddings = outputs\n",
    "            \n",
    "            if self.use_evidential:\n",
    "                loss_pred = self.evidential_loss(pred, labels)\n",
    "            else:\n",
    "                loss_pred = F.cross_entropy(pred, labels)\n",
    "            \n",
    "            loss_center = self.center_loss(embeddings, labels)\n",
    "        \n",
    "        return loss_pred + loss_center\n",
    "    \n",
    "    def get_predictions(self, outputs):\n",
    "        if isinstance(outputs, tuple):\n",
    "            pred = outputs[0]\n",
    "        else:\n",
    "            pred = outputs\n",
    "        \n",
    "        if self.use_evidential:\n",
    "            alpha = pred + 1\n",
    "            S = alpha.sum(dim=1, keepdim=True)\n",
    "            probs = alpha / S\n",
    "            return torch.argmax(probs, dim=1)\n",
    "        else:\n",
    "            return torch.argmax(pred, dim=1)\n",
    "    \n",
    "    def fit(self, train_loader, val_loader, epochs: int = 40, lr: float = 1e-4,\n",
    "            use_sam: bool = True, primary_metric: str = 'recall',\n",
    "            patience: int = 12, min_delta: float = 0.0005):\n",
    "        return super().fit(train_loader, val_loader, epochs, lr, use_sam=True,\n",
    "                          primary_metric=primary_metric, patience=patience, min_delta=min_delta)\n",
    "    \n",
    "    def train_epoch(self, train_loader, optimizer, scaler=None, scheduler=None):\n",
    "        self.model.train()\n",
    "        self.mixup_enabled = True\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        from .techniques import SAM\n",
    "        is_sam = isinstance(optimizer, SAM)\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if is_sam:\n",
    "                outputs = self.forward(images, labels)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.first_step(zero_grad=True)\n",
    "                \n",
    "                outputs = self.forward(images, labels)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.second_step(zero_grad=True)\n",
    "            else:\n",
    "                outputs = self.forward(images, labels)\n",
    "                loss = self.compute_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            if scheduler and isinstance(scheduler, (\n",
    "                torch.optim.lr_scheduler.OneCycleLR,\n",
    "                torch.optim.lr_scheduler.SequentialLR\n",
    "            )):\n",
    "                scheduler.step()\n",
    "            \n",
    "            running_loss += loss.detach().item() * images.size(0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                preds = self.get_predictions(outputs)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        from sklearn.metrics import accuracy_score, recall_score\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "        acc = accuracy_score(all_labels, all_preds) * 100\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        return avg_loss, acc, recall\n",
    "\n",
    "\n",
    "# Classifier registry\n",
    "CLASSIFIER_MAP = {\n",
    "    'baseline': BaselineClassifier,\n",
    "    'progressive': ProgressiveClassifier,\n",
    "    'evidential': EvidentialClassifier,\n",
    "    'metric_learning': MetricLearningClassifier,\n",
    "    'regularized': RegularizedClassifier,\n",
    "    'attention_enhanced': AttentionEnhancedClassifier,\n",
    "    'progressive_evidential': ProgressiveEvidentialClassifier,\n",
    "    'clinical_grade': ClinicalGradeClassifier,\n",
    "    'hybrid_transformer': HybridTransformerClassifier,\n",
    "    'ultimate': UltimateRecallOptimizedClassifier,\n",
    "}\n",
    "\n",
    "\n",
    "def test_all_classifiers_on_model(\n",
    "    model_name: str,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    classifiers: List[str] = 'all',\n",
    "    class_names: Optional[List[str]] = None,\n",
    "    epochs: int = 30,\n",
    "    lr: float = 1e-4,\n",
    "    primary_metric: str = 'recall',\n",
    "    device: str = 'cuda',\n",
    "    save_dir: str = './classifier_comparison'\n",
    "):\n",
    "    \n",
    "    # Create save directory\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Default class names\n",
    "    if class_names is None:\n",
    "        class_names = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']\n",
    "    \n",
    "    # Handle 'all' option\n",
    "    if classifiers == 'all':\n",
    "        classifiers_to_test = list(CLASSIFIER_MAP.keys())\n",
    "    else:\n",
    "        classifiers_to_test = [c.lower().replace(' ', '_') for c in classifiers]\n",
    "    \n",
    "    # Validate classifier names\n",
    "    invalid = [c for c in classifiers_to_test if c not in CLASSIFIER_MAP]\n",
    "    if invalid:\n",
    "        available = ', '.join(CLASSIFIER_MAP.keys())\n",
    "        raise ValueError(f\"Invalid classifiers: {invalid}. Available: {available}\")\n",
    "    \n",
    "    # Results storage\n",
    "    results = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"TESTING MULTIPLE CLASSIFIERS ON: {model_name.upper()}\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Primary Metric: {primary_metric.upper()}\")\n",
    "    print(f\"Testing {len(classifiers_to_test)} classifiers\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    # Test each classifier\n",
    "    for clf_name in classifiers_to_test:\n",
    "        print(\"\\n\" + \"‚ñà\"*100)\n",
    "        print(f\"‚ñà{'':^98}‚ñà\")\n",
    "        print(f\"‚ñà{f'TESTING: {clf_name.upper()} on {model_name}':^98}‚ñà\")\n",
    "        print(f\"‚ñà{'':^98}‚ñà\")\n",
    "        print(\"‚ñà\"*100 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            # Create classifier\n",
    "            start_time = time.time()\n",
    "            \n",
    "            clf_class = CLASSIFIER_MAP[clf_name]\n",
    "            classifier = clf_class(\n",
    "                model_name=model_name,\n",
    "                num_classes=len(class_names),\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            # Train\n",
    "            print(f\"\\n{'‚îÄ'*100}\")\n",
    "            print(\"TRAINING PHASE\")\n",
    "            print(f\"{'‚îÄ'*100}\\n\")\n",
    "            \n",
    "            # Determine if should use SAM\n",
    "            use_sam = clf_name in ['clinical_grade', 'ultimate']\n",
    "            \n",
    "            history = classifier.fit(\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                epochs=epochs,\n",
    "                lr=lr,\n",
    "                use_sam=use_sam,\n",
    "                primary_metric=primary_metric,\n",
    "                patience=10,\n",
    "                min_delta=0.001 if clf_name != 'ultimate' else 0.0005\n",
    "            )\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Test\n",
    "            print(f\"\\n{'‚îÄ'*100}\")\n",
    "            print(\"TESTING PHASE\")\n",
    "            print(f\"{'‚îÄ'*100}\\n\")\n",
    "            \n",
    "            test_results = classifier.evaluate(test_loader, class_names=class_names)\n",
    "            \n",
    "            # Store results\n",
    "            result_entry = {\n",
    "                'Classifier': clf_name,\n",
    "                'Model': model_name,\n",
    "                f'Test_{primary_metric.capitalize()}': test_results.get(primary_metric, 0.0),\n",
    "                'Test_Recall': test_results['recall'],\n",
    "                'Test_Accuracy': test_results['accuracy'],\n",
    "                'Test_Precision': test_results['precision'],\n",
    "                'Test_F1': test_results['f1'],\n",
    "                f'Best_Val_{primary_metric.capitalize()}': classifier.best_metric_value,\n",
    "                'Best_Val_Recall': classifier.best_recall,\n",
    "                'Best_Val_Accuracy': classifier.best_acc,\n",
    "                'Training_Time_Min': training_time / 60,\n",
    "                'Total_Epochs': len(history) if isinstance(history, list) else epochs,\n",
    "            }\n",
    "            \n",
    "            # Per-class recall\n",
    "            for i, class_name in enumerate(class_names):\n",
    "                result_entry[f'{class_name}_Recall'] = test_results['per_class_recall'][i]\n",
    "            \n",
    "            results.append(result_entry)\n",
    "            \n",
    "            # Save model\n",
    "            save_path = f\"{save_dir}/{clf_name}_{model_name}.pth\"\n",
    "            classifier.save(save_path)\n",
    "            print(f\"\\n‚úì Model saved to: {save_path}\")\n",
    "            \n",
    "            # Success message\n",
    "            print(f\"\\n{'‚ïî'*100}\")\n",
    "            print(f\"‚úì {clf_name.upper()} COMPLETE\")\n",
    "            print(f\"  Test {primary_metric.capitalize()}: {test_results[primary_metric if primary_metric in test_results else 'recall']:.4f} ‚òÖ\")\n",
    "            print(f\"  Test Accuracy: {test_results['accuracy']:.2f}%\")\n",
    "            print(f\"  Training Time: {training_time/60:.1f} minutes\")\n",
    "            print(f\"{'‚ïö'*100}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚úó ERROR testing {clf_name}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            # Record failure\n",
    "            results.append({\n",
    "                'Classifier': clf_name,\n",
    "                'Model': model_name,\n",
    "                f'Test_{primary_metric.capitalize()}': 0.0,\n",
    "                'Test_Recall': 0.0,\n",
    "                'Test_Accuracy': 0.0,\n",
    "                'Test_Precision': 0.0,\n",
    "                'Test_F1': 0.0,\n",
    "                f'Best_Val_{primary_metric.capitalize()}': 0.0,\n",
    "                'Best_Val_Recall': 0.0,\n",
    "                'Best_Val_Accuracy': 0.0,\n",
    "                'Training_Time_Min': 0.0,\n",
    "                'Total_Epochs': 0,\n",
    "                'Error': str(e)\n",
    "            })\n",
    "\n",
    "        finally :\n",
    "            # Cleanup\n",
    "            del classifier\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Sort by primary metric\n",
    "    sort_col = f'Test_{primary_metric.capitalize()}'\n",
    "    if sort_col not in results_df.columns:\n",
    "        sort_col = 'Test_Recall'\n",
    "    \n",
    "    results_df = results_df.sort_values(sort_col, ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Add rank\n",
    "    results_df.insert(0, 'Rank', range(1, len(results_df) + 1))\n",
    "    \n",
    "    # Save results\n",
    "    results_path = f\"{save_dir}/comparison_{model_name}.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"FINAL RESULTS SUMMARY - {model_name.upper()} (Ranked by {primary_metric.upper()})\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    # Display table\n",
    "    display_cols = ['Rank', 'Classifier', sort_col, 'Test_Accuracy', 'Test_F1', 'Training_Time_Min']\n",
    "    print(results_df[display_cols].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"üèÜ WINNER: {results_df.iloc[0]['Classifier'].upper()}\")\n",
    "    print(f\"   {primary_metric.capitalize()}: {results_df.iloc[0][sort_col]:.4f}\")\n",
    "    print(f\"   Accuracy: {results_df.iloc[0]['Test_Accuracy']:.2f}%\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    print(f\"\\nüìä Full results saved to: {results_path}\\n\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "def test_single_classifier(\n",
    "    classifier_name: str,\n",
    "    model_name: str,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    class_names: Optional[List[str]] = None,\n",
    "    epochs: int = 30,\n",
    "    lr: float = 1e-4,\n",
    "    primary_metric: str = 'recall',\n",
    "    device: str = 'cuda'\n",
    "):\n",
    "    \n",
    "    classifier_name = classifier_name.lower().replace(' ', '_')\n",
    "    \n",
    "    if classifier_name not in CLASSIFIER_MAP:\n",
    "        available = ', '.join(CLASSIFIER_MAP.keys())\n",
    "        raise ValueError(f\"Unknown classifier: '{classifier_name}'. Available: {available}\")\n",
    "    \n",
    "    if class_names is None:\n",
    "        class_names = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Testing: {classifier_name.upper()} on {model_name}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Create classifier\n",
    "    clf_class = CLASSIFIER_MAP[classifier_name]\n",
    "    classifier = clf_class(\n",
    "        model_name=model_name,\n",
    "        num_classes=len(class_names),\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    use_sam = classifier_name in ['clinical_grade', 'ultimate']\n",
    "    \n",
    "    history = classifier.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        use_sam=use_sam,\n",
    "        primary_metric=primary_metric,\n",
    "        patience=10\n",
    "    )\n",
    "    \n",
    "    # Test\n",
    "    test_results = classifier.evaluate(test_loader, class_names=class_names)\n",
    "    \n",
    "    return test_results, classifier\n",
    "\n",
    "\n",
    "def compare_classifiers(results_df: pd.DataFrame, save_path: Optional[str] = None):\n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Test Recall comparison\n",
    "    ax = axes[0, 0]\n",
    "    sns.barplot(data=results_df, x='Test_Recall', y='Classifier', ax=ax, palette='viridis')\n",
    "    ax.set_title('Test Recall (PRIMARY METRIC)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.axvline(x=0.99, color='r', linestyle='--', label='Target (0.99)')\n",
    "    ax.legend()\n",
    "    \n",
    "    # 2. Test Accuracy comparison\n",
    "    ax = axes[0, 1]\n",
    "    sns.barplot(data=results_df, x='Test_Accuracy', y='Classifier', ax=ax, palette='rocket')\n",
    "    ax.set_title('Test Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Accuracy (%)')\n",
    "    \n",
    "    # 3. Test F1 comparison\n",
    "    ax = axes[1, 0]\n",
    "    sns.barplot(data=results_df, x='Test_F1', y='Classifier', ax=ax, palette='mako')\n",
    "    ax.set_title('Test F1 Score', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('F1 Score')\n",
    "    \n",
    "    # 4. Training time comparison\n",
    "    ax = axes[1, 1]\n",
    "    sns.barplot(data=results_df, x='Training_Time_Min', y='Classifier', ax=ax, palette='flare')\n",
    "    ax.set_title('Training Time', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Time (minutes)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\nüìä Comparison plot saved to: {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def list_available_classifiers():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AVAILABLE CLASSIFIERS (11 Total)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nADVANCED (Research-Grade):\")\n",
    "    advanced = [\n",
    "        ('baseline', 'Standard CrossEntropy'),\n",
    "        ('evidential', 'Uncertainty quantification'),\n",
    "        ('metric_learning', 'Prototypes + Triplet + Center Loss'),\n",
    "        ('regularized', 'Manifold Mixup + Label Smoothing'),\n",
    "        ('attention_enhanced', 'SE Blocks + Cosine Classifier'),\n",
    "        ('progressive', 'Sophisticated 3-phase fine-tuning'),\n",
    "        ('progressive_evidential', 'Progressive + Evidential'),\n",
    "        ('clinical_grade', 'Clinical deployment (5 techniques + SAM) ‚≠ê'),\n",
    "        ('hybrid_transformer', 'CNN + Transformer hybrid'),\n",
    "        ('ultimate', 'All 10 techniques (maximum recall) ‚≠ê‚≠ê‚≠ê')\n",
    "    ]\n",
    "    \n",
    "    for i, (name, desc) in enumerate(advanced, 3):\n",
    "        print(f\"  {i}. {name:<22} - {desc}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Usage Examples:\")\n",
    "    print(\"  test_all_classifiers_on_model('resnet18', ..., classifiers='all')\")\n",
    "    print(\"  test_all_classifiers_on_model('resnet18', ..., classifiers=['simple', 'progressive'])\")\n",
    "    print(\"  test_single_classifier('ultimate', 'resnet18', ...)\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return list(CLASSIFIER_MAP.keys())\n",
    "\n",
    "\n",
    "# Convenience function\n",
    "def get_classifier_info(classifier_name: str):\n",
    "    classifier_name = classifier_name.lower().replace(' ', '_')\n",
    "    \n",
    "    if classifier_name not in CLASSIFIER_MAP:\n",
    "        available = ', '.join(CLASSIFIER_MAP.keys())\n",
    "        raise ValueError(f\"Unknown classifier: '{classifier_name}'. Available: {available}\")\n",
    "    \n",
    "    info_map = {\n",
    "        'baseline': {\n",
    "            'name': 'BaselineClassifier',\n",
    "            'category': 'Basic',\n",
    "            'description': 'Basic timm wrapper with AdamW + OneCycleLR',\n",
    "            'speed': 'Fast',\n",
    "            'use_case': 'Simple baseline for comparisons'\n",
    "        },\n",
    "        'progressive': {\n",
    "            'name': 'ProgressiveClassifier',\n",
    "            'category': 'Basic',\n",
    "            'description': 'Sophisticated 3-phase discriminative fine-tuning',\n",
    "            'speed': 'Medium',\n",
    "            'use_case': 'High-quality training with architecture awareness'\n",
    "        },\n",
    "        'evidential': {\n",
    "            'name': 'EvidentialClassifier',\n",
    "            'category': 'Advanced',\n",
    "            'description': 'Evidential deep learning for uncertainty quantification',\n",
    "            'speed': 'Medium',\n",
    "            'use_case': 'When you need uncertainty scores'\n",
    "        },\n",
    "        'ultimate': {\n",
    "            'name': 'UltimateRecallOptimizedClassifier',\n",
    "            'category': 'Advanced',\n",
    "            'description': 'All 10 research techniques combined',\n",
    "            'speed': 'Slow',\n",
    "            'use_case': 'Maximum recall for critical medical diagnosis'\n",
    "        },\n",
    "        # Add more as needed...\n",
    "    }\n",
    "    \n",
    "    return info_map.get(classifier_name, {\n",
    "        'name': CLASSIFIER_MAP[classifier_name].__name__,\n",
    "        'category': 'Advanced',\n",
    "        'description': 'Research-grade classifier',\n",
    "        'speed': 'Medium',\n",
    "        'use_case': 'Advanced training'\n",
    "    })\n",
    "\n",
    "\n",
    "# Classifier registry for string-based access\n",
    "CLASSIFIER_REGISTRY = {\n",
    "    'baseline': BaselineClassifier,\n",
    "    'evidential': EvidentialClassifier,\n",
    "    'metric_learning': MetricLearningClassifier,\n",
    "    'regularized': RegularizedClassifier,\n",
    "    'attention_enhanced': AttentionEnhancedClassifier,\n",
    "    'progressive': ProgressiveClassifier,\n",
    "    'progressive_evidential': ProgressiveEvidentialClassifier,\n",
    "    'clinical_grade': ClinicalGradeClassifier,\n",
    "    'hybrid_transformer': HybridTransformerClassifier,\n",
    "    'ultimate': UltimateRecallOptimizedClassifier,\n",
    "}\n",
    "\n",
    "\n",
    "def get_classifier(classifier_type: str = 'simple') :\n",
    "    classifier_type = classifier_type.lower().replace(' ', '_')\n",
    "    \n",
    "    if classifier_type not in CLASSIFIER_REGISTRY:\n",
    "        available = ', '.join(CLASSIFIER_REGISTRY.keys())\n",
    "        raise ValueError(\n",
    "            f\"Unknown classifier type: '{classifier_type}'. \"\n",
    "            f\"Available: {available}\"\n",
    "        )\n",
    "    \n",
    "    return CLASSIFIER_REGISTRY[classifier_type]\n",
    "\n",
    "\n",
    "def list_classifiers(display : bool = False):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AVAILABLE CLASSIFIERS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nADVANCED:\")\n",
    "    print(\"  baseline            - Standard CrossEntropy\")\n",
    "    print(\"  evidential          - Uncertainty quantification\")\n",
    "    print(\"  metric_learning     - Prototypes + Triplet + Center Loss\")\n",
    "    print(\"  regularized         - Manifold Mixup + Label Smoothing\")\n",
    "    print(\"  attention_enhanced  - SE Blocks + Cosine Classifier\")\n",
    "    print(\"  progressive         - Sophisticated 3-phase fine-tuning\")\n",
    "    print(\"  progressive_evidential - Progressive + Evidential\")\n",
    "    print(\"  clinical_grade      - Clinical deployment (5 techniques) ‚≠ê\")\n",
    "    print(\"  hybrid_transformer  - CNN + Transformer hybrid\")\n",
    "    print(\"  ultimate            - All 10 techniques (maximum recall) ‚≠ê‚≠ê‚≠ê\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return list(CLASSIFIER_REGISTRY.keys())\n",
    "\n",
    "\n",
    "def test_model(model_name, model, loader, classes, experiment_name, logger, history = None,\n",
    "               visualizer=None, use_tta=False):\n",
    "    \n",
    "    # Create visualizer (test.py creates its own - cross_validation doesn't need to!)\n",
    "    if not visualizer :\n",
    "        img_size = get_img_size(model_name)\n",
    "        transform = get_base_transformations(img_size)\n",
    "        visualizer = Visualizer(\n",
    "            experiment_name=experiment_name,\n",
    "            model_name=model_name,\n",
    "            class_names=classes,\n",
    "            transform=transform,\n",
    "            logger=logger\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # Check if this is a classifier object (has evaluate method)\n",
    "    if hasattr(model, 'evaluate'):\n",
    "        logger.info(f\"--- Detected Classifier Object: Using classifier.evaluate() ---\")\n",
    "        \n",
    "        # Use classifier's built-in evaluate method\n",
    "        result = model.evaluate(loader, class_names=classes)\n",
    "        y_true = np.array(result[\"labels\"])\n",
    "        y_pred = np.array(result[\"preds\"])\n",
    "        y_prob = np.array(result[\"probs\"])\n",
    "        accuracy = result[\"accuracy\"]\n",
    "        recall = result[\"recall\"]\n",
    "        precision = result[\"precision\"]\n",
    "        f1 = result[\"f1\"]\n",
    "        per_class_recall = result[\"per_class_recall\"]\n",
    "        cm = result[\"confusion_matrix\"]\n",
    "        classification_report_ = result[\"report\"]\n",
    "        pytorch_model = model.model if hasattr(model, 'model') else None\n",
    "    \n",
    "    else:\n",
    "        # Raw PyTorch model - use legacy test logic\n",
    "        logger.info(f\"--- Detected Raw PyTorch Model: Using standard testing ---\")\n",
    "        \n",
    "        from .augmentation import TTAWrapper\n",
    "        \n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        \n",
    "        if use_tta:\n",
    "            logger.info(\"Using Test-Time Augmentation (TTA)\")\n",
    "            tta_model = TTAWrapper(model, num_augmentations=5)\n",
    "        \n",
    "        # Inference Loop\n",
    "        with torch.inference_mode():\n",
    "            for images, labels in loader:\n",
    "                images = images.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                \n",
    "                if use_tta:\n",
    "                    probs = tta_model(images)\n",
    "                    preds = torch.argmax(probs, dim=1)\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    probs = torch.softmax(outputs, dim=1)\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        # Convert to numpy\n",
    "        y_true = np.array(all_labels)\n",
    "        y_pred = np.array(all_preds)\n",
    "        y_prob = np.array(all_probs)\n",
    "        \n",
    "        # Calculate Metrics\n",
    "        accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        per_class_recall = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        classification_report_ = classification_report(y_true, y_pred, target_names=classes, digits=4)\n",
    "        pytorch_model = model\n",
    "    \n",
    "    # NaN handling\n",
    "    if np.isnan(y_prob).any():\n",
    "        logger.warning(\"‚ö†Ô∏è  NaN detected in probability outputs!\")\n",
    "        n_classes = len(classes)\n",
    "        y_prob = np.nan_to_num(y_prob, nan=1.0/n_classes)\n",
    "    \n",
    "    # Verify probabilities sum to 1.0\n",
    "    prob_sums = y_prob.sum(axis=1)\n",
    "    if not np.allclose(prob_sums, 1.0, atol=1e-3):\n",
    "        logger.warning(\"‚ö†Ô∏è  Normalizing probabilities to sum=1.0\")\n",
    "        y_prob = y_prob / prob_sums[:, np.newaxis]\n",
    "    \n",
    "    # ROC AUC\n",
    "    try:\n",
    "        if len(classes) == 2:\n",
    "            roc_auc = roc_auc_score(y_true, y_prob[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')\n",
    "    except:\n",
    "        logger.warning(f\"Unexpected error in ROC AUC calculation: {e}\")\n",
    "        roc_auc = 0.0\n",
    "    \n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    corrcoef = matthews_corrcoef(y_true, y_pred)\n",
    "    jaccard = jaccard_score(y_true, y_pred, average=\"weighted\")\n",
    "    \n",
    "    # Generate Report\n",
    "    report_path = os.path.join(REPORTS_DIR, f\"{experiment_name}.txt\")\n",
    "    \n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(f\"===== COMPREHENSIVE ANALYSIS REPORT: {experiment_name} =====\\n\\n\")\n",
    "        f.write(f\"Test-Time Augmentation: {'Enabled' if use_tta else 'Disabled'}\\n\\n\")\n",
    "        f.write(\"--- Overall Performance ---\\n\")\n",
    "        f.write(f\"Overall Accuracy: {accuracy:.2f}%\\n\")\n",
    "        f.write(f\"Overall Recall: {recall:.4f}\\n\")\n",
    "        f.write(f\"Overall Precision: {precision:.4f}\\n\")\n",
    "        f.write(f\"Overall F1: {f1:.4f}\\n\")\n",
    "        f.write(f\"\\nPer-Class Recall\")\n",
    "        for i, (name, rec) in enumerate(zip(classes, per_class_recall)):\n",
    "            f.write(f\"  {name}: {rec:.4f}\")\n",
    "        f.write(f\"Macro ROC AUC:    {roc_auc:.4f}\\n\")\n",
    "        f.write(f\"Cohen's Kappa:    {kappa:.4f}\\n\")\n",
    "        f.write(f\"Matthews Correlation Coefficient (MCC): {corrcoef:.4f}\\n\")\n",
    "        f.write(f\"Jaccard Score:    {jaccard:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"--- Detailed Per-Class Metrics ---\\n\")\n",
    "        f.write(classification_report_)\n",
    "        \n",
    "        f.write(\"\\n--- Per-Class Specificity & Confusion Matrix Stats ---\\n\")\n",
    "        \n",
    "        for i, class_name in enumerate(classes):\n",
    "            tp = cm[i, i]\n",
    "            fp = cm[:, i].sum() - tp\n",
    "            fn = cm[i, :].sum() - tp\n",
    "            tn = cm.sum() - (tp + fp + fn)\n",
    "            \n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "            f.write(f\"{class_name:<20}: Specificity: {specificity:.4f}, \"\n",
    "                    f\"TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}\\n\")\n",
    "    \n",
    "    logger.info(f\"Report saved to: {report_path}\")\n",
    "    \n",
    "    # Generate ALL visualizations\n",
    "    logger.info(\"Generating comprehensive visualizations...\")\n",
    "    \n",
    "    visualizer.generate_all_plots(\n",
    "        y_true=y_true,\n",
    "        y_prob=y_prob,\n",
    "        history=history,\n",
    "        model=pytorch_model,\n",
    "        test_loader=loader,\n",
    "        xai_samples=NUM_SAMPLES_TO_ANALYSE  # Enable GradCAM/LIME/SHAP\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Testing and visualization complete\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "        'per_class_recall': per_class_recall,\n",
    "        'roc_auc': roc_auc,\n",
    "        'kappa': kappa,\n",
    "        'corrcoef': corrcoef,\n",
    "        'jaccard': jaccard,\n",
    "        'y_true': y_true,\n",
    "        'y_prob': y_prob,\n",
    "        'y_pred': y_pred,\n",
    "    }\n",
    "\n",
    "\n",
    "class Cross_Validator:\n",
    "    \n",
    "    def __init__(self, model_names, logger: Logger, model_classifier_map=None):\n",
    "        self.model_names = model_names\n",
    "        self.results = []\n",
    "        self.logger = logger\n",
    "        self.master_file = os.path.join(RESULTS_DIR, \"master_results.csv\")\n",
    "        self.models_dir = os.path.join(RESULTS_DIR, \"best_models\")\n",
    "        \n",
    "        # Classifier mapping\n",
    "        self.model_classifier_map = model_classifier_map or {}\n",
    "        \n",
    "        os.makedirs(self.models_dir, exist_ok = True)\n",
    "        \n",
    "        self.logger.debug(f\"Models for cross-validation: {self.model_names}\")\n",
    "        self.logger.debug(f\"Classifier mapping: {self.model_classifier_map}\")\n",
    "        self.logger.debug(f\"Master results file: {self.master_file}\")\n",
    "\n",
    "    def run(self):\n",
    "        master_df = None\n",
    "        if os.path.exists(self.master_file):\n",
    "            master_df = pd.read_csv(self.master_file)\n",
    "            self.logger.debug(f\"Master df exists -> {self.master_file}\")\n",
    "        \n",
    "        # Load dataset ONCE\n",
    "        self.logger.info(\"\\n\" + \"=\"*80)\n",
    "        self.logger.info(\"LOADING DATASET (ONCE FOR ALL MODELS)\")\n",
    "        self.logger.info(\"=\"*80)\n",
    "        self.logger.info(f\"Loading dataset from: {DATA_DIR}\")\n",
    "        \n",
    "        temp_transform = transforms.Compose([transforms.ToTensor()])\n",
    "        base_dataset = FullDataset(DATA_DIR, temp_transform)\n",
    "\n",
    "        training_history = []\n",
    "        \n",
    "        targets = np.array(base_dataset.targets)\n",
    "        classes = base_dataset.classes\n",
    "        \n",
    "        self.logger.info(f\"Total samples: {len(targets)}\")\n",
    "        self.logger.debug(f\"Classes found: {classes}\")\n",
    "        \n",
    "        # Calculate Class Weights (same for all models)\n",
    "        class_counts = np.bincount(targets)\n",
    "        total_samples = len(targets)\n",
    "        class_weights = total_samples / (len(classes) * class_counts)\n",
    "        class_weights_tensor = torch.FloatTensor(class_weights).to(DEVICE)\n",
    "        \n",
    "        self.logger.info(\"=\"*80)\n",
    "        self.logger.info(\"CLASS DISTRIBUTION & WEIGHTS:\")\n",
    "        for i, cls in enumerate(classes):\n",
    "            self.logger.info(f\"  {cls:<20}: {class_counts[i]:>4} samples \"\n",
    "                           f\"({100*class_counts[i]/total_samples:>5.1f}%) | Weight: {class_weights[i]:.3f}\")\n",
    "        self.logger.info(\"=\"*80)\n",
    "        \n",
    "        # Train/Test Split ONCE (same test set for all models)\n",
    "        train_val_indices, test_indices = train_test_split(\n",
    "            np.arange(len(targets)),\n",
    "            test_size=TEST_SPLIT,\n",
    "            stratify=targets,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        self.logger.info(f\"Data split: {len(train_val_indices)} train/val, {len(test_indices)} test\")\n",
    "        \n",
    "        train_val_targets = targets[train_val_indices]\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Train each model\n",
    "        for model_name in self.model_names:\n",
    "            # Get classifier type (default to 'simple' if not specified)\n",
    "            classifier_type_input = self.model_classifier_map.get(model_name, 'baseline')\n",
    "\n",
    "            if classifier_type_input == \"all\" :\n",
    "                classifiers_to_be_used = list_classifiers()\n",
    "            elif isinstance(classifier_type_input, str) :\n",
    "                classifiers_to_be_used = [classifier_type_input]\n",
    "            \n",
    "            for classifier_type in classifiers_to_be_used :\n",
    "                self._run_classifier(\n",
    "                    model_name=model_name,\n",
    "                    classifier_type=classifier_type,\n",
    "                    base_dataset=base_dataset,\n",
    "                    train_val_indices=train_val_indices,\n",
    "                    test_indices=test_indices,\n",
    "                    targets=targets,\n",
    "                    classes=classes,\n",
    "                    skf=skf,\n",
    "                    master_df=master_df\n",
    "                )\n",
    "        \n",
    "        self.logger.info(\"\\n>>> Batch Complete.\")\n",
    "\n",
    "    def _run_classifier(self, model_name, classifier_type, base_dataset, \n",
    "                       train_val_indices, test_indices, targets, classes, skf, master_df):\n",
    "        experiment_name = f\"{model_name}_classifier={classifier_type}_metric={OPTIMIZE_METRIC}\"\n",
    "        checkpoint_path = os.path.join(self.models_dir, f\"{experiment_name}_best_weights.pth\")\n",
    "        fold_checkpoint_path = os.path.join(self.models_dir, f\"{experiment_name}_best_fold.pth\")\n",
    "        \n",
    "        self.logger.info(\"\\n\" + \"=\"*80)\n",
    "        self.logger.info(f\"STARTING EXPERIMENT: {experiment_name.upper()}\")\n",
    "        self.logger.info(f\"Using Classifier: {classifier_type}\")\n",
    "        self.logger.info(\"=\"*80)\n",
    "\n",
    "        # Skip if already completed\n",
    "        if master_df is not None:\n",
    "            existing = master_df[\n",
    "                (master_df['model_name'] == model_name) &\n",
    "                (master_df.get('classifier_type', '') == classifier_type) &\n",
    "                (master_df.get('optimize_metric', '') == OPTIMIZE_METRIC)\n",
    "            ]\n",
    "            if not existing.empty:\n",
    "                self.logger.info(\">> Experiment already completed. Skipping.\")\n",
    "                self.logger.info(existing.to_string())\n",
    "                self.logger.info(\"=\"*80)\n",
    "                return\n",
    "\n",
    "        # Get image size and transforms\n",
    "        img_size = get_img_size(model_name)\n",
    "        self.logger.debug(f\"Image size for {model_name}: {img_size}\")\n",
    "        model_transform = get_base_transformations(img_size)\n",
    "\n",
    "        # Load dataset\n",
    "        self.logger.info(f\"Loading dataset from: {DATA_DIR}\")\n",
    "        full_dataset = FullDataset(DATA_DIR, model_transform)\n",
    "\n",
    "        self.logger.info(f\"\\n=== K-Fold Cross-Validation: {model_name} with {classifier_type} ===\")\n",
    "        \n",
    "        train_val_targets = targets[train_val_indices]\n",
    "        fold_metrics = []\n",
    "        training_histoy = []\n",
    "        best_fold = 0\n",
    "        best_fold_metric = 0.0\n",
    "        \n",
    "        # Create fresh classifier instance\n",
    "        classifier_class = get_classifier(classifier_type)\n",
    "        \n",
    "        # K-Fold Cross-Validation\n",
    "        for fold, (fold_train_idx_rel, fold_val_idx_rel) in enumerate(skf.split(train_val_indices, train_val_targets)):\n",
    "            self.logger.info(f\"\\n  [Fold {fold+1}/{NFOLDS}]\")\n",
    "            \n",
    "            # Get absolute indices\n",
    "            train_idx = train_val_indices[fold_train_idx_rel]\n",
    "            val_idx = train_val_indices[fold_val_idx_rel]\n",
    "            \n",
    "            # Create datasets and loaders\n",
    "            train_ds = Subset(full_dataset, train_idx)\n",
    "            val_ds = Subset(full_dataset, val_idx)\n",
    "            \n",
    "            train_loader = DataLoader(\n",
    "                train_ds,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=NUM_WORKERS,\n",
    "                pin_memory=PIN_MEMORY,\n",
    "                persistent_workers=PERSISTENT_WORKERS if NUM_WORKERS > 0 else False\n",
    "            )\n",
    "            val_loader = DataLoader(\n",
    "                val_ds,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=False,\n",
    "                num_workers=NUM_WORKERS,\n",
    "                pin_memory=PIN_MEMORY,\n",
    "                persistent_workers=PERSISTENT_WORKERS if NUM_WORKERS > 0 else False\n",
    "            )\n",
    "            classifier : BaseClassifier = classifier_class(\n",
    "                model_name=model_name,\n",
    "                num_classes=len(classes),\n",
    "                device=DEVICE\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"  Training {classifier_type} classifier...\")\n",
    "            \n",
    "            # Determine if should use SAM (only for clinical_grade and ultimate)\n",
    "            use_sam = classifier_type in ['clinical_grade', 'ultimate']\n",
    "            \n",
    "            # Train classifier - ALL HAVE SAME INTERFACE!\n",
    "            history = classifier.fit(\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                epochs=EPOCHS,\n",
    "                lr=LR,\n",
    "                use_sam=use_sam,\n",
    "                primary_metric=OPTIMIZE_METRIC,\n",
    "                patience=PATIENCE,\n",
    "                min_delta=MIN_DELTA_METRIC,\n",
    "                checkpoint_path = checkpoint_path\n",
    "            )\n",
    "            training_histoy.append(history)\n",
    "            \n",
    "            # Get best metrics from this fold\n",
    "            fold_metric_value = classifier.best_metric_value\n",
    "            \n",
    "            self.logger.info(\n",
    "                f\"  Fold {fold+1} Best {OPTIMIZE_METRIC.capitalize()}: {fold_metric_value:.4f} | \"\n",
    "                f\"Acc: {classifier.best_acc:.2f}% | \"\n",
    "                f\"Recall: {classifier.best_recall:.4f}\"\n",
    "            )\n",
    "            \n",
    "            fold_metrics.append({\n",
    "                'fold': fold + 1,\n",
    "                f'val_{OPTIMIZE_METRIC}': fold_metric_value,\n",
    "                'val_acc': classifier.best_acc,\n",
    "                'val_recall': classifier.best_recall,\n",
    "                'val_f1': classifier.best_f1\n",
    "            })\n",
    "            \n",
    "            # Track best fold\n",
    "            if fold_metric_value > best_fold_metric:\n",
    "                best_fold = fold\n",
    "                best_fold_metric = fold_metric_value\n",
    "                # Save best fold checkpoint\n",
    "                classifier.save(fold_checkpoint_path)\n",
    "                self.logger.info(f\"  ‚úì Best fold so far! Checkpoint saved.\")\n",
    "            \n",
    "            # Cleanup\n",
    "            del classifier, train_loader, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            self.logger.info(f\"Fold {fold + 1} cleanup completed\")\n",
    "        \n",
    "        # Aggregate fold results\n",
    "        fold_df = pd.DataFrame(fold_metrics)\n",
    "        aggregate_fold_results = {\n",
    "            f'mean_fold_{OPTIMIZE_METRIC}': fold_df[f'val_{OPTIMIZE_METRIC}'].mean(),\n",
    "            f'std_fold_{OPTIMIZE_METRIC}': fold_df[f'val_{OPTIMIZE_METRIC}'].std(),\n",
    "            'mean_fold_acc': fold_df['val_acc'].mean(),\n",
    "            'std_fold_acc': fold_df['val_acc'].std(),\n",
    "            'mean_fold_recall': fold_df['val_recall'].mean(),\n",
    "            'mean_fold_f1': fold_df['val_f1'].mean(),\n",
    "        }\n",
    "        \n",
    "        self.logger.info(f\"\\n  K-Fold Summary:\")\n",
    "        self.logger.info(f\"    Mean {OPTIMIZE_METRIC.capitalize()}: {aggregate_fold_results[f'mean_fold_{OPTIMIZE_METRIC}']:.4f} \"\n",
    "                        f\"¬± {aggregate_fold_results[f'std_fold_{OPTIMIZE_METRIC}']:.4f}\")\n",
    "        self.logger.info(f\"    Best Fold: {best_fold+1} ({best_fold_metric:.4f})\")\n",
    "        \n",
    "        # Test on held-out test set using best fold model\n",
    "        self.logger.info(f\"\\n  Loading best fold model for final evaluation...\")\n",
    "        \n",
    "        test_subset = Subset(full_dataset, test_indices)\n",
    "        test_loader = DataLoader(\n",
    "            test_subset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=PIN_MEMORY,\n",
    "            persistent_workers=PERSISTENT_WORKERS if NUM_WORKERS > 0 else False\n",
    "        )\n",
    "        \n",
    "        # Load best fold checkpoint\n",
    "        eval_classifier : BaseClassifier = classifier_class(\n",
    "            model_name=model_name,\n",
    "            num_classes=len(classes),\n",
    "            device=DEVICE\n",
    "        )\n",
    "        eval_classifier.load(checkpoint_path)\n",
    "        # eval_classifier.load(fold_checkpoint_path)\n",
    "        \n",
    "        self.logger.info(f\"\\n  Final evaluation on test set...\")\n",
    "        metrics = test_model(\n",
    "            model_name=model_name,\n",
    "            model=eval_classifier,\n",
    "            loader=test_loader,\n",
    "            classes=classes,\n",
    "            experiment_name=experiment_name,\n",
    "            history=training_histoy,\n",
    "            logger=self.logger,\n",
    "            use_tta=False\n",
    "        )\n",
    "        \n",
    "        final_accuracy = metrics[\"accuracy\"]\n",
    "        final_recall = metrics[\"recall\"]\n",
    "        \n",
    "        self.logger.info(f\"\\n  Final Test Results:\")\n",
    "        self.logger.info(f\"    Accuracy: {final_accuracy:.2f}%\")\n",
    "        self.logger.info(f\"    Recall: {final_recall:.4f}\")\n",
    "        self.logger.info(f\"    Precision: {metrics['precision']:.4f}\")\n",
    "        self.logger.info(f\"    F1: {metrics['f1']:.4f}\")\n",
    "        \n",
    "        # Save results in unified format\n",
    "        results_data = {\n",
    "            'model_name': [model_name],\n",
    "            'classifier_type': [classifier_type],\n",
    "            'optimize_metric': [OPTIMIZE_METRIC],\n",
    "            'pretrained': [PRETRAINED],\n",
    "            'best_val_metric': [f\"{best_fold_metric:.4f}\"],\n",
    "            'final_test_accuracy': [f\"{final_accuracy:.2f}%\"],\n",
    "            'final_test_recall': [f\"{final_recall:.4f}\"],\n",
    "            'total_epochs': [EPOCHS],\n",
    "            'batch_size': [BATCH_SIZE],\n",
    "            'n_splits': [NFOLDS],\n",
    "            **aggregate_fold_results\n",
    "        }\n",
    "        \n",
    "        pd.DataFrame(results_data).to_csv(\n",
    "            self.master_file,\n",
    "            mode='a',\n",
    "            header=not os.path.exists(self.master_file),\n",
    "            index=False\n",
    "        )\n",
    "        self.logger.info(f\"\\nResults appended to {self.master_file}\")\n",
    "        self.logger.info(f\"EXPERIMENT FINISHED: {experiment_name.upper()}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del eval_classifier, test_loader, full_dataset\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "def run_batch():\n",
    "    models = __models_list__\n",
    "    classifier_map = __classifier_map__\n",
    "\n",
    "    logger = Logger(\"batch_\" + str(hash(str(models)))[:8])\n",
    "    logger.info(f\"Starting validation for {models}\")\n",
    "    logger.info(f\"Classifier mapping: {classifier_map}\")\n",
    "    \n",
    "    try:\n",
    "        validator = Cross_Validator(\n",
    "            models,\n",
    "            logger,\n",
    "            model_classifier_map=classifier_map\n",
    "        )\n",
    "        validator.run()\n",
    "        logger.info(\"Validation complete\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Batch failed: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_batch()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subprocess_runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subprocess(models_list, classifier_map=None):\n",
    "    \"\"\"Run a batch of models in a subprocess with classifier mapping.\n",
    "    \n",
    "    Args:\n",
    "        models_list: List of model names to train\n",
    "        classifier_map: Dict mapping model_name -> classifier_type\n",
    "                       If None, uses DEFAULT_CLASSIFIER for all models\n",
    "    \"\"\"\n",
    "    script_filename = \"temp_runner.py\"\n",
    "    script_path = os.path.join(\"module\", script_filename)\n",
    "    \n",
    "    # Create classifier map for this batch\n",
    "    if classifier_map is None:\n",
    "        batch_classifier_map = {\n",
    "            model: DEFAULT_CLASSIFIER for model in models_list\n",
    "        }\n",
    "    else :\n",
    "        # Filter to only include models in this batch\n",
    "        batch_classifier_map = {\n",
    "            model: classifier_map.get(model, DEFAULT_CLASSIFIER)\n",
    "            for model in models_list\n",
    "        }\n",
    "    \n",
    "    script_content = SUBPROCESS_TEMPLATE.replace(\"__models_list__\", str(models_list)) \\\n",
    "                                        .replace(\"__classifier_map__\", str(batch_classifier_map))\n",
    "    \n",
    "    with open(script_path, \"w\") as f:\n",
    "        f.write(script_content)\n",
    "    \n",
    "    print(f\"üöÄ Launching: {models_list}\")\n",
    "    print(f\"   Classifiers: {batch_classifier_map}\")\n",
    "    print(f\"   Timeout: {SUBPROCESS_TIMEOUT/3600:.1f}h\")\n",
    "\n",
    "    try:\n",
    "        module_path = f\"module.{script_filename[:-3]}\"\n",
    "        subprocess.run(\n",
    "            [sys.executable, \"-m\", module_path], \n",
    "            check=True,\n",
    "            timeout=SUBPROCESS_TIMEOUT\n",
    "        )\n",
    "    finally:\n",
    "        if os.path.exists(script_path):\n",
    "            os.remove(script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "queue_runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_queue(batches : str | list = \"fetch\", classifier_map=None):\n",
    "    \"\"\"Run all model batches with classifier mapping.\n",
    "    \n",
    "    Args:\n",
    "        classifier_map : Dict mapping model_name -> classifier_type\n",
    "                       If None, uses DEFAULT_CLASSIFIER for all models\n",
    "        batches : list of strings containing correct timm compatible model names, suggesting batches of model names.\n",
    "                    \"fetch\" means batches will be fetched from pre defined function.\n",
    "                    \"auto\" means batches will be taken as keys of the classifier_map dict, with each key being a batch.\n",
    "    \"\"\"\n",
    "    run_id = f\"RUN_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "    total_batches = completed = timeout = failed = 0\n",
    "    errors = []\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING BATCH PROCESSING: {run_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if classifier_map:\n",
    "        print(f\"\\nClassifier Mapping ({len(classifier_map)} custom):\")\n",
    "        for model, clf in classifier_map.items():\n",
    "            print(f\"  {model}: {clf}\")\n",
    "    print(f\"Default Classifier: {DEFAULT_CLASSIFIER}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    try:\n",
    "        batches = batches or get_model_batches()\n",
    "        total_batches = len(batches)\n",
    "\n",
    "        for i, batch in enumerate(batches):\n",
    "            print(f\"\\n{'>'*80}\")\n",
    "            print(f\">>> Batch {i+1}/{total_batches}\")\n",
    "            print(f\">>> Models: {batch}\")\n",
    "            print(f\"{'>'*80}\")\n",
    "            \n",
    "            try:\n",
    "                run_subprocess(batch, classifier_map)\n",
    "                completed += 1\n",
    "                print(f\"\\n‚úÖ Batch {i+1}/{total_batches} completed successfully\\n\")\n",
    "            except subprocess.TimeoutExpired:\n",
    "                timeout += 1\n",
    "                errors.append(f\"Batch {i+1} TIMEOUT after {SUBPROCESS_TIMEOUT/3600:.1f}h\")\n",
    "                print(f\"\\n‚è∞ Batch {i+1} TIMEOUT\\n\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                failed += 1\n",
    "                errors.append(f\"Batch {i+1} ERROR: {e}\")\n",
    "                print(f\"\\n‚ùå Batch {i+1} failed with error\\n\")\n",
    "            except Exception as e:\n",
    "                failed += 1\n",
    "                errors.append(f\"Batch {i+1}: {traceback.format_exc()}\")\n",
    "                print(f\"\\n‚ùå Batch {i+1} failed with exception\\n\")\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è User interrupt detected\\n\")\n",
    "    \n",
    "    # Summary Report\n",
    "    summary = f\"\"\"\n",
    "{'='*80}\n",
    "EXECUTION SUMMARY\n",
    "{'='*80}\n",
    "Run ID: {run_id}\n",
    "Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Results:\n",
    "  ‚úì Completed: {completed}/{total_batches}\n",
    "  ‚è∞ Timeout:   {timeout}\n",
    "  ‚ùå Failed:    {failed}\n",
    "  \n",
    "Success Rate: {100*completed/total_batches if total_batches > 0 else 0:.1f}%\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "    print(summary)\n",
    "    \n",
    "    # Save detailed report\n",
    "    report_file = f\"REPORT_{run_id}.txt\"\n",
    "    with open(report_file, \"w\") as f:\n",
    "        f.write(summary)\n",
    "        f.write(\"\\n\\nDETAILED ERRORS:\\n\")\n",
    "        f.write(\"\\n\".join(errors) if errors else \"No errors\")\n",
    "    \n",
    "    print(f\"üìÑ Detailed report saved to: {report_file}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'run_id': run_id,\n",
    "        'completed': completed,\n",
    "        'timeout': timeout,\n",
    "        'failed': failed,\n",
    "        'total': total_batches\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zip_helper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_output_directory(summary = None):\n",
    "    \"\"\"Archive output directory after successful completion.\"\"\"\n",
    "    import zipfile\n",
    "    \n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        print(f\"‚ö†Ô∏è Output directory '{OUTPUT_DIR}' not found. Nothing to zip.\")\n",
    "        return\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "    zip_name = f\"Results_{timestamp}.zip\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ARCHIVING RESULTS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            files = 0\n",
    "            for root, dirs, filelist in os.walk(OUTPUT_DIR):\n",
    "                for file in filelist:\n",
    "                    filepath = os.path.join(root, file)\n",
    "                    zipf.write(filepath, os.path.relpath(filepath, '.'))\n",
    "                    files += 1\n",
    "        \n",
    "        size_mb = os.path.getsize(zip_name) / (1024*1024)\n",
    "        print(f\"‚úÖ Archive created: {zip_name}\")\n",
    "        print(f\"   Size: {size_mb:.1f} MB\")\n",
    "        print(f\"   Files: {files}\")\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"EXECUTION SUMMARY\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        if summary :\n",
    "            status = \"‚úÖ SUCCESS\" if summary['completed'] == summary['total'] else \"‚ö†Ô∏è PARTIAL\"\n",
    "            print(f\"\\nStatus: {status}\")\n",
    "            print(f\"Run ID: {summary['run_id']}\")\n",
    "            print(f\"Completed: {summary['completed']}/{summary['total']} batches\")\n",
    "            print(f\"Timeout: {summary['timeout']}\")\n",
    "            print(f\"Failed: {summary['failed']}\")\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"üéâ ALL PROCESSING COMPLETE!\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Archive creation failed: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MAIN EXECUTION\n",
    "# # Run all model batches with classifier configuration\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"ADNI CROSS-VALIDATION PIPELINE\")\n",
    "# print(\"=\"*80)\n",
    "# print(f\"Total Models: {len(heavy_models + medium_models + light_models)}\")\n",
    "# print(f\"Total Batches: {len(get_model_batches())}\")\n",
    "# print(f\"Timeout per Batch: {SUBPROCESS_TIMEOUT/3600:.1f}h\")\n",
    "# print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# # Run with classifier mapping\n",
    "# summary = run_queue(classifier_map=MODEL_CLASSIFIER_MAP)\n",
    "\n",
    "# # Archive results\n",
    "# zip_output_directory(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meet\n",
    "# MODEL_CLASSIFIER_MAP = {\n",
    "#     'resnet18': 'all'\n",
    "# }\n",
    "# MODEL_CLASSIFIER_MAP = {\n",
    "#     'resnet18': 'ultimate'\n",
    "# }\n",
    "# MODEL_CLASSIFIER_MAP = {\n",
    "#     'resnet50.a1_in1k': ['evidental', \"progressive_evidental\"],\n",
    "#     \"resnext50_32x4d.a1h_in1k\" : [\"clinical_grade\", \"metric_learning\"]\n",
    "# }\n",
    "\n",
    "# Prince\n",
    "# MODEL_CLASSIFIER_MAP = {\n",
    "#     \"swin_base_patch4_window7_224.ms_in22k_ft_in1k\" : [\"evidental\", \"progressive\", \"attention_enhanced\"]\n",
    "# }\n",
    "# MODEL_CLASSIFIER_MAP = {\n",
    "#     \"tf_efficientnet_b4.ns_jft_in1k\" : ['evidental', \"progressive_evidental\"]\n",
    "# }\n",
    "summary = run_queue(\"auto\", MODEL_CLASSSIFIE_MAP)\n",
    "zip_output_directory(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
